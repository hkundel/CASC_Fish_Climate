---
title: "WI_file cleanup"
author: "Mike Verhoeven"
date: "`r Sys.Date()`"
output: html_document
---


## State data
### Read in
From GDrive ?, not doing this for now, having issues with direct read from 
GDrive. Current startegy requires connect to GDrive for desktop. This code
is hard to WI data, can we create a more flexible/adaptable approach?

```{r}

# This code is still broken-- it is supposed to draw a file straight form the web to workspace
# import_id <- drive_get("https://drive.google.com/file/d/1huPEj93VZ01-q4YGcIVvHBR2YhbGMPUu/view?usp=share_link")
#  import_id %>%
#  drive_read_string() %>%
#    read_csv_arrow()




files_list <- list.files(path = "E:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/WI_Data/WI_raw_disaggregated_data", pattern = ".+\\.csv") #grabs only.csv files
files_list

n <- length(files_list)

for(i in 1:n) {
  #i = 1
  filei <- word(gsub(".csv","", files_list[i]), start = -1, sep = fixed("/"))
  #this does those two steps in one package
  assign(filei ,
          data.table(read_csv_arrow(paste0("E:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/WI_Data/WI_raw_disaggregated_data/",
                                          files_list[i]))))
  
  # note we want to review a sorted list of column names to check misspelling etc.
  # we still need to use the columns with names like col_name_length_in, or known_units
  
  
  cde %>% # call data explainer file
    filter(`new_file_name`== filei)%>% #keep only the row relevant to this file
    select_if(~ !any(is.na(.))) %>% 
    transpose(keep.names = "newname") %>% 
    rename("oldname" = V1) %>% 
    assign("names", ., envir = .GlobalEnv)
  
  #see if any column names will not have a match! 
  # IF any pop FALSE, force stop and revist of data explainer ()
  # - e.g., named something "total catch" when actual column name was "total_catch"
  print(
    cbind(colnames(get(filei)),
          colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
    )
  )
  
  # break the loop if the current file has column names not in the data explainer
  if (all(cbind(colnames(get(filei)),  colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ])[,2]) == FALSE ) break
  
  # append old col names into new "notes" columns:
  get(filei)[ , (names[ str_detect(newname, "notes") , oldname   ,  ]) := Map(paste, colnames(.SD), .SD, sep = ':') , .SDcols =  names[ str_detect(newname, "notes") , oldname   ,  ] ]
  
  #now rename that file's colnames
  setnames(get(filei), colnames(get(filei)), names[!str_detect(newname,"unique_row_key")] [match(names(get(filei)),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )
  
  #append all other data from data explainer
  unusedbits <- 
    data.table(
      matrix(
        rep(names[ !newname %in% colnames(get(filei)) , oldname , ],
            each = nrow(get(filei))
        ),
        nrow = nrow(get(filei)),
        dimnames = list(rep(NA,nrow(get(filei))),
                        names[ !newname %in% colnames(get(filei)) , newname , ])
        )
      )
  
  #add all not yet used columns from data explainer:
  get(filei)[ , (names[ !newname %in% colnames(get(filei)) , newname , ]) := unusedbits[] ]

  #confirm import of files:  
  print(paste(filei ,"added to workspace" ))  
  
}  

# gsub(".csv","", WI_files_list[i])

```

Get new column names from data explainer for all files
```{r}
#for a state file, display column names - 

# gsub(".csv","", WI_files_list)

# #oldnames
# cde %>% # call data explainer file
#   filter(`new_file_name`== gsub(".csv","", WI_files_list)[1])%>% #keep only the row relevant to this file
#   select_if(~ !any(is.na(.)))%>% #drop columns that contain NA (because that means df doesn't contain that info)
#   make_clean_names() %>% 
#   assign("oldnames", ., envir = .GlobalEnv)


# select(14:25) #keep only columns of relevance (remove our file tracking and urls)

# display our new names for that set - (esp. need to ID no matches)

# cde %>% # call data explainer file
#   filter(`new_file_name`== gsub(".csv","", WI_files_list)[1])%>% #keep only the row relevant to this file
#   select_if(~ !any(is.na(.)))%>% #drop columns that contain NA (because that means df doesn't contain that info)
#   colnames() %>% 
#   assign("newnames", ., envir = .GlobalEnv)
# 
# cbind(oldnames,newnames)

#this does those two steps in one package
# note we want to review a sorted list of column names to check misspelling etc.
# cde %>% # call data explainer file
#   filter(`new_file_name`== gsub(".csv","", WI_files_list)[1])%>% #keep only the row relevant to this file
#   select_if(~ !any(is.na(.))) %>% 
#   transpose(keep.names = "newname") %>% 
#   rename("oldname" = V1) %>% 
#   assign("names", ., envir = .GlobalEnv)

#see if nay column names will not have a match! 
# IF any pop FALSE, force stop and revist of data explainer ()
# - e.g., named something "total catch" when actual column name was "total_catch"
# 
# cbind(colnames(get(gsub(".csv","", WI_files_list)[1])),
#       colnames(get(gsub(".csv","", WI_files_list)[1])) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
# )

#now rename that file's colnames
# setnames(get(gsub(".csv","", WI_files_list)[1]), colnames(get(gsub(".csv","", WI_files_list)[1])), names[!str_detect(newname,"unique_row_key")] [match(names(get(gsub(".csv","", WI_files_list)[1])),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )
# 
# 

# note for files that have items in the "garbage bin" column, we NEED a different process where we remove garbage columns after 'filter' but before dropping na columns


```



Make a "flat file"
```{r}

names(wi_inland_fishobservations_19Mar2021)
  names(wi_inland_lenage_19Mar2021)








```



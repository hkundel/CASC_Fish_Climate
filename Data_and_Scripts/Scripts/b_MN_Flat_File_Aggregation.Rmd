---
title: "MN_Flat_File_Aggregation"
author: "Holly Kundel & Mike Verhoeven"
date: "`r Sys.Date()`"
output: html_document
---
# Preamble

libraries
```{r}
library(arrow)
library(readr)
library(dplyr)
library(stringr)
library(data.table)
library(janitor)
library(tidyr)
library(lubridate)
library(bit64)

options(scipen = 999)
```

Update 13 June 2023 Mike: 
- We've got new indiv fish data, so we'll connect to that in building our "flat file"
- mn_fish_2022only_31May2023.csv file has issues (e.g., doesn't include any un-aged fish)
- mn_cpue_2022only_31May2023.csv file has issues (e.g., doesn't include any un-aged fish)
- our goal today is a functional mn flat file

Update 7 June 2023 Mike: 
- uses fread() b/c arrow_read_csv() seems to be choking on the mn_fish_2022only_31May2023.csv file.
- I perused Holly's work and I think I might need to start fresh here. 



# Load Data


* note Holly has to change "G" in file paths to "D" 
```{r}

files_list <- list.files(path = "D:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data", pattern = ".+\\.csv") #grabs only.csv files
files_list

#manually drop that 2022 fish
files_list <- files_list[!(files_list %in% c("mn_cpue_2022only_31May2023.csv", "mn_fish_2022only_31May2023.csv"))]



n <- length(files_list)

for(i in 1:n) {
  #i = 3
  filei <- word(gsub(".csv","", files_list[i]), start = -1, sep = fixed("/"))
  #this does those two steps in one package
  assign(filei ,
          fread(paste0("D:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data/",
                                          files_list[i])))
  
  # note we want to review a sorted list of column names to check misspelling etc.
  # we still need to use the columns with names like col_name_length_in, or known_units
  
  
  cde %>% # call data explainer file
    filter(`new_file_name`== filei)%>% #keep only the row relevant to this file
    select_if(~ !any(is.na(.))) %>% 
    transpose(keep.names = "newname") %>% 
    rename("oldname" = V1) %>% 
    assign("names", ., envir = .GlobalEnv)
  
  #see if any column names will not have a match! 
  # IF any pop FALSE, force stop and revist of data explainer ()
  # - e.g., named something "total catch" when actual column name was "total_catch"
  print(
    cbind(colnames(get(filei)),
          colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
    )
  )
  
  #this line is where the warnings are coming from
  # break the loop if the current file has column names not in the data explainer
  if (all(cbind(colnames(get(filei)),  colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ])[,2]) == FALSE ) break
  
  # append old col names into new "notes" columns:
  get(filei)[ , (names[ str_detect(newname, "notes") , oldname   ,  ]) := Map(paste, colnames(.SD), .SD, sep = ':') , .SDcols =  names[ str_detect(newname, "notes") , oldname   ,  ] ]
  
  #now rename that file's colnames
  setnames(get(filei), colnames(get(filei)), names[!str_detect(newname,"unique_row_key")] [match(names(get(filei)),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )
  
  #append all other data from data explainer
  unusedbits <- 
    data.table(
      matrix(
        rep(names[ !newname %in% colnames(get(filei)) , oldname , ],
            each = nrow(get(filei))
        ),
        nrow = nrow(get(filei)),
        dimnames = list(rep(NA,nrow(get(filei))),
                        names[ !newname %in% colnames(get(filei)) , newname , ])
        )
      )
  
  #add all not yet used columns from data explainer:
  get(filei)[ , (names[ !newname %in% colnames(get(filei)) , newname , ]) := unusedbits[] ]

  #confirm import of files:  
  print(paste(filei ,"added to workspace" ))  
  
} 

# check warnings and see if we can make it go away
#print some kind of completion confirmation?

```


# Effort Merge

```{r}

# this rbind puts together 3 files that are not equivalent (ef data is true effort data (each row is gear in a survey) and the other 2 are catch files (each row is a species in a a gear in a survey))
#create an issue for this idea
## This highlights the idea that catch and effort are coming to our doorstep two ways: 
#1: effort data contains NO corresponding catch info (the MN EF data look like this)
#2: effort data contain some or all of the catch data (most mn efforts contain catch summaries, eg., number of individuals per species)

## As such, we need some way to steer our workflow through the parsing of those data. We need different streams for each type (in all likelihood--unless we can have a workflow that works on all types)
effort <- rbindlist(list(rbindlist(list(mn_gde_gsh_fish_effort_03May2022,
                                    mn_fish_effort_03May2022),
                               fill = TRUE,
                               use.names = TRUE),
                     mn_ef_lmb_smb_effort_26Aug2022),
                fill = TRUE,
                use.names = TRUE)

#make all into effort files
# we want to match the same data per row format as the EF effort data. We can see (after some sleuthing) that that dataset has a unique key in the combo of (lake_id, date.2(survey date), gear, survey type)
mn_ef_lmb_smb_effort_26Aug2022[ ,  .N , .(lake_id, date.2, sampling_method_abbrev, survey_type.1)] #here date.2 is the survey date
mn_gde_gsh_fish_effort_03May2022[ , .N , .(lake_id, date.1, sampling_method_abbrev, survey_type.1) ] #here date.1 is the survey date
mn_fish_effort_03May2022[          , .N , .(lake_id, date.1, sampling_method_abbrev, survey_type.1) ]

#drop cpue
## create an issue for this idea
  #general gears
  mn_fish_effort_03May2022[ , cpue , ] #view CPUE
  mn_fish_effort_03May2022[ , round(total_count/total_effort_1.1,2) , ]
  sum(!mn_fish_effort_03May2022[ , cpue == round(total_count/total_effort_1.1,2) , ])# the number of cases where DNR calcd CPUE does not == catch/effort
  
  #this is odd, suggests something wonky w/ dnr measured cpues
  mn_fish_effort_03May2022[ , cpue := NULL ,]
  
  #deep and shallow Gns
  sum(!mn_gde_gsh_fish_effort_03May2022[ , cpue == round(total_count/total_effort_1.1,2) , ])# the number of cases where DNR calcd CPUE does not == catch/effort
  ## create an issue for this idea
  #this is odd, suggests something wonky w/ dnr measured cpues
  mn_gde_gsh_fish_effort_03May2022[ , cpue := NULL ,]

  #tag the species for easy col selection:
  mn_gde_gsh_fish_effort_03May2022[ , species.1 := paste("taxa", species.1, sep = "_")]
  mn_fish_effort_03May2022[ , species.1 := paste("taxa", species.1, sep = "_")]

# species, total count and cpue are only species specific components (cpue has been dropped)
mn_fish_effort_03May2022 <- dcast(mn_fish_effort_03May2022 , ... ~ species.1 , value.var = "total_count", fill = 0)
mn_gde_gsh_fish_effort_03May2022 <- dcast(mn_gde_gsh_fish_effort_03May2022 , ... ~ species.1 , value.var = "total_count", fill = 0)


# this rbind puts together 3 files that should now be equivalent (each row is gear in a survey)
effort <- rbindlist(list(rbindlist(list(mn_gde_gsh_fish_effort_03May2022,
                                    mn_fish_effort_03May2022),
                               fill = TRUE,
                               use.names = TRUE),
                     mn_ef_lmb_smb_effort_26Aug2022),
                fill = TRUE,
                use.names = TRUE)



#fix up dates
# catch[ , as.IDate(unique(word(date.1, 1, sep = fixed(" "))), format = "%m/%d/%Y") , ]
effort[ , date_clean :=  as.IDate(word(date.1, 1, sep = fixed(" ")), format = "%m/%d/%Y"),]
effort[ is.na(date_clean), ]

effort[ , hist(yday(date_clean)) ,]
effort[ , hist(year(date_clean)) ,]

#check other fields
names(effort)

#move no-taxa to the left
colnames(effort)[!str_detect(colnames(effort), "taxa_")]
setcolorder(effort, colnames(effort)[!str_detect(colnames(effort), "taxa_")])

#tidy sampling methods
effort[ , .N , sampling_method ]
effort[ , .N , .(sampling_method_abbrev)]
#do we have abbreviated gears where missing in ^?
effort[is.na(sampling_method), unique(sampling_method_abbrev)]

#backfill the sampling_method column from codes:
effort[is.na(sampling_method) &
        sampling_method_abbrev == "GSH",
      sampling_method := "Shallow gill nets"]
effort[is.na(sampling_method) &
        sampling_method_abbrev == "GDE",
      sampling_method := "Deep gill nets"]
effort[is.na(sampling_method) &
        sampling_method_abbrev == "TN",
      sampling_method := "Standard trap nets"]
effort[is.na(sampling_method) &
        sampling_method_abbrev == "GN",
      sampling_method := "Standard gill nets"]

#ditch the abbreviation/code column
effort[ , sampling_method_abbrev := NULL, ]

#tidy up the FWB ID and verify that it is same resolution as DOW_ID
effort[ , unique(word(garbage_bin_notes.1, sep = ":")) ,]
effort[word(garbage_bin_notes.1, sep = ":")=="FISHERIES_WATERBODY_ID" , .N ]
effort[ word(garbage_bin_notes.1, sep = ":")=="FISHERIES_WATERBODY_ID"  , length(unique(lake_id)) , garbage_bin_notes.1 ][V1 > 1]
effort[word(garbage_bin_notes.1, sep = ":")=="FISHERIES_WATERBODY_ID", "lake_id.2" := garbage_bin_notes.1 , ]
effort[word(garbage_bin_notes.1, sep = ":")=="FISHERIES_WATERBODY_ID", garbage_bin_notes.1 := NA , ]



sort(names(effort))

#year
effort[ , unique(year) , ]
effort[ is.na(year),]
 sum(effort[ ,year != year(date_clean)])
##consider adding this as an issue, could sleuth around the dates and see if other date cols match better, try DT[ , hist(year-year(date.1))]

#effortunits
effort[ , unique(effort_units.1) ,]
effort[effort_units.1 == "knownunit_number_of_nets" , effort_units.1 := "knownunit_number_of_net_nights" , ]


#unique row key fields can be dropped
# these weights are associated with multiple fish, so maybe a mean or median--we're going to drop them (we can't assess anything from aggregated weights)
effort[ , `:=` (unique_row_key.1 = NULL,
               unique_row_key.2 = NULL,
               unique_row_key.3 = NULL,
               unique_row_key.4 = NULL)]



#rbindlist of the species matrix resulted in an imperfect fill of zeros in non EF data (should only be 0 or n_taxa(129) ):
unique(rowSums(is.na(effort[ , .SD , .SDcols = names(effort)[str_detect(names(effort), "taxa_")] ])))

#for all non EF data, fill NAs with zeros
setnafill(effort, fill = 0, cols = colnames(effort)[str_detect(names(effort), "taxa_")] ) #fill all of species matrix w/ zeros
#ef data now have zero catches in the taxa_cols, lets overwrite those w/ NAs
effort[new_file_name == "mn_ef_lmb_smb_effort_26Aug2022", names(effort)[str_detect(names(effort), "taxa_")] := NA , ]

#check work
unique(rowSums(is.na(effort[ , .SD , .SDcols = names(effort)[str_detect(names(effort), "taxa_")] ])))


#how many walleye expected in our results from GN? This number matches that generated on 8 June 
sum(effort[ str_detect(sampling_method, "gill net")  , taxa_walleye , ])


#any surveys with nothing caught?
names(effort)[str_detect(names(effort), "taxa_")]
any(rowSums(effort[ , .SD , .SDcols = names(effort)[str_detect(names(effort), "taxa_")] ], na.rm =T)==0)
nrow(effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022"][rowSums(effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022", .SD , .SDcols = names(effort)[str_detect(names(effort), "taxa_")] ], na.rm = T)==0])

# add a nothing caught and a no_aggd_catch_data column
effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022" , nothing_caught := rowSums(effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022" , .SD , .SDcols = names(effort)[str_detect(names(effort), "taxa_")] ])==0  ,]
effort[new_file_name == "mn_ef_lmb_smb_effort_26Aug2022", no_aggd_catch_provided := TRUE , ]
effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022", no_aggd_catch_provided := FALSE]


effort[nothing_caught==T] #2 surveys really did catch NADA
# Holly - What did these look like in the raw data?

#now expand to long data:(this code generates HUGE files) We should skip this step. Instead, lets set aside that species catch matrix, and use it later in the cross

# effort_expanded <- melt(effort, measure.vars = patterns("^taxa"), variable.name = "species", value.name = "count"  )[order(lake_id, date_clean, sampling_method, survey_type.1), ,]
# effort_expanded[species == "taxa_walleye", sum(count, na.rm = T)] #529259
# effort_expanded_presences_only <- uncount(effort_expanded[no_aggd_catch_provided==F], count, .remove = F, .id = "id") # this will drop all zeros, must include a subset excluding the data for which counts were not provided--this will otherwise snag the weights arg (can't weight by NA)
# effort_expanded[count==0, id := NA]
# nrow(rbind(catch_expanded[count==0],catch_expanded_presences_only))
# catch_expanded <- rbind(catch_expanded[count==0],catch_expanded_presences_only)
# rm(catch_expanded_presences_only)

keycols_and_catch_mat <- c("lake_id", "date_clean", "sampling_method", "survey_type.1", names(effort)[str_detect(names(effort), "taxa_")])
DNR_calcd_catch <- effort[  , .SD , .SDcols = keycols_and_catch_mat  ]
rm(keycols_and_catch_mat)

#drop catch mat from effort data
effort[ , c( names(effort)[str_detect(names(effort), "taxa_")]) := NULL , ]

#clean some crumbs out of ws:
rm(mn_ef_lmb_smb_effort_26Aug2022, mn_fish_effort_03May2022, mn_gde_gsh_fish_effort_03May2022)

#clean up lake_ids
effort[ , lake_id_chr := lake_id ]
effort[ , lake_id := as.integer(lake_id)]


```


# Merge Indiv Fish Data

```{r}

#now tie the indiv fish data to these effort records

# the EF fish data have corrupted fish attributes (so we'll overwrite all of those with NAs for now)
badcols <- c("sample_id", "length.1", "weight.1", "age", "young_of_year", "sex", "reproductive_condition", "gear_data_notes.1" )
mn_ef_lmb_smb_catch_26Aug2022[ , (badcols) :=  NA , ]

#check work
mn_ef_lmb_smb_catch_26Aug2022

# make EF survey_id into the same data format as others
mn_ef_lmb_smb_catch_26Aug2022[ , survey_id := as.integer64(survey_id) ,]

#first, merge the indiv fish data
indiv_fish <- rbindlist(list(mn_ef_lmb_smb_catch_26Aug2022, 
                             mn_r1_gillnet_indiv_fish_20oct2020,
                             mn_r2_gillnet_indiv_fish_20oct2020,
                             mn_r3_gillnet_indiv_fish_20oct2020,
                             mn_r4_gillnet_indiv_fish_20oct2020,
                             mn_shallgillnet_indiv_fish_20oct2020,
                             mn_deepgillnet_indiv_fish_20oct2020,
                             mn_r1_trapnet_indiv_fish_20oct2020,
                             mn_r2_trapnet_indiv_fish_20oct2020,
                             mn_r3_trapnet_indiv_fish_20oct2020,
                             mn_r4_trapnet_indiv_fish_20oct2020),
                               fill = TRUE,
                               use.names = TRUE) #will have to check this tomorrow, but seems like it worked

#inspect merge
colnames(indiv_fish)
sort(colnames(indiv_fish))

setcolorder(indiv_fish, c("lake_id", "date.2", "date.1", "sampling_method_abbrev", "survey_type.1")) 

indiv_fish[ , .N , .(sampling_method_abbrev, species.1)  ]
indiv_fish[ species.1 == "WAE", .N , .(sampling_method_abbrev)  ] # here we can see that we've not got "all gears" data bc WAE have def been captured in EF (and other gears)
indiv_fish[ species.1 == "WAE", .N , .(sampling_method_abbrev)  ][ , sum(N) , ]

#drop data inputs for fish data
rm(mn_ef_lmb_smb_catch_26Aug2022, 
                             mn_r1_gillnet_indiv_fish_20oct2020,
                             mn_r2_gillnet_indiv_fish_20oct2020,
                             mn_r3_gillnet_indiv_fish_20oct2020,
                             mn_r4_gillnet_indiv_fish_20oct2020,
                             mn_shallgillnet_indiv_fish_20oct2020,
                             mn_deepgillnet_indiv_fish_20oct2020,
                             mn_r1_trapnet_indiv_fish_20oct2020,
                             mn_r2_trapnet_indiv_fish_20oct2020,
                             mn_r3_trapnet_indiv_fish_20oct2020,
                             mn_r4_trapnet_indiv_fish_20oct2020)



#to-do:
# make these clean: "lake_id", "date_clean", "sampling_method", "survey_type.1"

#dates (from data explainer we know that date.2 is survey date, but only available in non-EF files)
indiv_fish[ , .(date.2, date.1), ]
indiv_fish[ , .N , .(date1=is.na(date.1), date2=is.na(date.2)) ]

#change dates to Idate:
indiv_fish[ , date_clean := as.IDate(date.2, format = "%m/%d/%Y") ,]

indiv_fish[ , summary(date_clean) , ]
indiv_fish[is.na(date_clean) == T , .N ]

indiv_fish[is.na(date_clean) == T , date_clean := as.IDate(date.1, format = "%m/%d/%Y") ,  ]

#check our work:
indiv_fish[ , summary(date_clean) , ]


#lake_id
indiv_fish[ , summary(lake_id) ,]
indiv_fish[ , str(lake_id), ]
effort[ , str(lake_id) ,]
#we can anticipate this being a problem when we go to merge the data


#tidy sampling methods
indiv_fish[ , .N , .(sampling_method_abbrev)]
effort[ , .N , sampling_method]
# git issue on this: inidv fish dat include backpack EF, but effort data do not

#create the sampling_method column from codes:
indiv_fish[sampling_method_abbrev == "GSH",
      sampling_method := "Shallow gill nets"]
indiv_fish[sampling_method_abbrev == "GDE",
      sampling_method := "Deep gill nets"]
indiv_fish[sampling_method_abbrev == "TN",
      sampling_method := "Standard trap nets"]
indiv_fish[sampling_method_abbrev == "GN",
      sampling_method := "Standard gill nets"]
indiv_fish[sampling_method_abbrev == "EF",
      sampling_method := "Standard electrofishing"]
indiv_fish[sampling_method_abbrev == "SEF",
      sampling_method := "Special sampling, electrofishing"]
indiv_fish[sampling_method_abbrev == "EFB",
      sampling_method := "Backpack electrofishing"]

#check
indiv_fish[ , .N , .(sampling_method_abbrev, sampling_method)]

#ditch the abbreviation/code column
indiv_fish[ , sampling_method_abbrev := NULL, ]

#survey.type

indiv_fish[ , .N , survey_type.1 ]
effort[ , .N , survey_type.1]

indiv_fish[ , .N , survey_type.1 ][ ,survey_type.1 , ]


# generate a type table (these codes can be found in MN_Data folder)
survey_type <- data.table(code = indiv_fish[ , .N , survey_type.1 ][ ,survey_type.1],
                          fullname = effort[ , .N , survey_type.1][ ,survey_type.1 ][c(2,4,3,9,1,10,7,5,6,12,8,14,11,13) ]
                                                         )
#execute
match(indiv_fish[ , survey_type.1], survey_type[,code])
survey_type[match(indiv_fish[ , survey_type.1], survey_type[,code]), fullname]

indiv_fish[ , survey_type.1 := survey_type[match(indiv_fish[ , survey_type.1], survey_type[,code]), fullname]   ,]
rm(survey_type)


# add an id to the indiv fish
indiv_fish[ , id := seq_len(.N) , .(lake_id, date_clean, sampling_method, survey_type.1, species.1) ]
indiv_fish[ , summary(id) ,]


#summarize ages
indiv_fish[ , .N , age ]
indiv_fish[ , .N , .(age=!is.na(age))]
#compare to the aged fish file:
#how many aged fish in the age data from Years we havem Gears we have, and lakes we have?
mn_aged_fish_v2_20apr2023[year(as.IDate(date.1, format = "%m/%d/%Y"))<2020 &
                            sampling_method_abbrev %in% c("GN", "GSH", "GDE", "TN", "EF", "SEF", "EFB") &
                            lake_id %in% indiv_fish[ ,unique(lake_id)], .N ,]
#same, now by year:
mn_aged_fish_v2_20apr2023[year(as.IDate(date.1, format = "%m/%d/%Y"))<2020 &
                            sampling_method_abbrev %in% c("GN", "GSH", "GDE", "TN", "EF", "SEF", "EFB") &
                            lake_id %in% indiv_fish[ ,unique(lake_id)], .N , year(as.IDate(date.1, format = "%m/%d/%Y"))]

#make an issue for this
#we need to check this out further, BUT generally 7/8 of the aged fish are represented in the indiv fish data we recieved

#merge the effort and indiv fish data


#scope the merge:
#99% of the wb in the effort data are represneted in indiv fish data
sum(indiv_fish[ , unique(lake_id) , ] %in% effort[ , unique(lake_id)])/effort[, length(unique(lake_id)) ,] 

#99% of the wb in the indiv fish data are represneted in  effort data
sum(indiv_fish[ , unique(lake_id) , ] %in% effort[ , unique(lake_id)])/indiv_fish[, length(unique(lake_id)) ,] 

# come back and scope out each individual key column match
# #20% coverage on the survey id column--this checks. Corey Geving said to stay away from these
# sum(age[ , .N , survey_id][,survey_id] %in% catch_expanded[ , unique(survey_id)])/age[, length(unique(survey_id)) ,] 
# 
# #49% coverage on the survey id column--this checks. Corey Geving said to stay away from these
# sum(age[ , .N , date_clean][,date_clean] %in% catch_expanded[ , unique(date_clean)])/age[, length(unique(date_clean)) ,] 

#we know that dates are a problem, can we schmooze that join?
# flatfish <- merge(catch_expanded,age, by = c("lake_id", "date_clean" , "sampling_method", "id", "species"), suffixes = c("_catch", "_age"))

flatfish <- merge(effort,indiv_fish, by = c("lake_id", "date_clean" , "sampling_method", "survey_type.1"), suffixes = c("_effort", "_indivfish"), all = T)

flatfish[ , .N , sampling_method]

flatfish[ (species.1 == "WAE" & sampling_method %in% c("Standard gill nets", "Shallow gill nets", "Deep gill nets")), .N, .(year = year(date_clean), age = !is.na(age), length = !is.na(length.1))][order(year, -N)]


#this chunk is what Mike thinks GH wants for today
names(flatfish)

#how many unique surveys exist for each category of has effort and has indiv fish data?
flatfish[ , length(unique(paste(lake_id, date_clean , sampling_method, survey_type.1))) , .(effort = !is.na(state_effort), indiv_fish_dat = !is.na(state_indivfish)) ]
  
#sum of all
  flatfish[ , length(unique(paste(lake_id, date_clean , sampling_method, survey_type.1))) , .(effort = !is.na(state_effort), indiv_fish_dat = !is.na(state_indivfish)) ][ , sum(V1) , ]

#for each of those with both effort and fish data, summarize catch by species (bring effort along too!)   
flatfish[ !is.na(state_effort)&!is.na(state_indivfish) , .N , .(lake_id, date_clean , sampling_method, survey_type.1, species.1, total_effort_1.1, effort_units.1) ]

  ## SIDEBAR! Flagging suspected issues
  #summarize the total effort for ef data
  flatfish[ effort_units.1 == "knownunit_hours" , hist(total_effort_1.1, breaks = 100) , ]# there are some very wierd values in here! Def want to flag these for review by a user! Here's an example of that:
  flatfish[ effort_units.1 == "knownunit_hours" , summary(total_effort_1.1) , ]
  flatfish[ effort_units.1 == "knownunit_hours" & !is.na(total_effort_1.1) , .(mean(total_effort_1.1) , sd(total_effort_1.1)) , ] #find sd and mean
  flatfish[ effort_units.1 == "knownunit_hours" & total_effort_1.1 > 1.464117 + (5*flatfish[ effort_units.1 == "knownunit_hours" & !is.na(total_effort_1.1) , sd(total_effort_1.1) , ])   , flagged_effort := TRUE , ] #flag records > 5 sd from mean
  flatfish[ , .N , flagged_effort]
  
  
#cast summarized catch data wide:
wide_complete <- dcast(flatfish[ !is.na(state_effort)&!is.na(state_indivfish) , .N , .(lake_id, date_clean , sampling_method, survey_type.1, species.1, total_effort_1.1, effort_units.1) ], ... ~ species.1 , value.var = "N", fill = 0)

# calc cpue for all wae
wide_complete[ , .(lake_id, date_clean , sampling_method, survey_type.1, total_effort_1.1, effort_units.1, WAE) ,]
wide_complete[ , wae_cpue := WAE/total_effort_1.1 , ]
# check mean cpue for gillnets
wide_complete[ str_detect(sampling_method, "gill net") , mean(wae_cpue) , sampling_method ]

  
flatfish[ species.1 == "WAE" , .N ,]

#where lake Id is a kittle no, we can drop those data (lake_id blank, lake_id_chr has kittle)
flatfish[ , .N , .(lake_id, lake_id_chr, date_clean , sampling_method, survey_type.1, total_effort_1.1, species.1)] 
  flatfish[!is.na(lake_id), .N , .(lake_id, lake_id_chr, date_clean , sampling_method, survey_type.1, total_effort_1.1, species.1)]
  flatfish <- flatfish[!is.na(lake_id)]

#lets get a cpue for walleye
  flatfish[ , , .(lake_id, date_clean , sampling_method, survey_type.1) ][]
    
  
flatfish[ , summary(date_clean) ,]

flatfish[ , hist(year(date_clean)) , ]

#walleye data product:
wae_complete_surveys <- wide_complete[ , .(lake_id, date_clean , sampling_method, survey_type.1, total_effort_1.1, effort_units.1, WAE) ,]
  
wae_records <- flatfish[ species.1 == "WAE" , ,] 

wae <- merge(wae_complete_surveys, wae_records, all = T, by = c("lake_id", "date_clean" , "sampling_method", "survey_type.1", "total_effort_1.1", "effort_units.1"))

wae[ , .N , .(lake_id, date_clean , sampling_method, survey_type.1, total_effort_1.1, effort_units.1, WAE) ] 


wae_gn_records <- wae[ str_detect(sampling_method, "gill nets") , , ]





#save to disk:

# saveRDS(effort, file = "Data_and_Scripts\\Data\\output\\mn_effort.rds")
# saveRDS(DNR_calcd_catch, file = "Data_and_Scripts\\Data\\output\\mn_dnr_calcd_catch.rds")
# saveRDS(indiv_fish, file = "Data_and_Scripts\\Data\\output\\mn_indivfish.rds")
# saveRDS(flatfish, file = "Data_and_Scripts\\Data\\output\\mn_flat_effort_indivfish_merge.rds")
# saveRDS(wae_gn_records, file = "Data_and_Scripts\\Data\\output\\mn_wae_gn.rds")




```


```{r}
# review what's available for WAE data, esp to compare to kelsey V's work:

wae_gn_records[ year(date_clean)%in% c(2018:2022)  , .N , .(year(date_clean), cpue = !is.na(count) ,length = !is.na(length.1), age = !is.na(age)) ][order(year)]



mn_fish_2022only_31May2023[ , .N , .(length = !is.na(length.1), age = !is.na(age) )  ]

KV_WAE <- fread("C:\\Users\\verh0064\\Desktop\\2019_WAE_RAW_ALLREGIONS_20200505.csv")

colnames(KV_WAE)
KV_WAE[ , .N , as.integer(FISH_COUNT)]

KV_WAE[ , FISH_COUNT := as.integer(FISH_COUNT) ,]

KV_WAE <-  uncount(KV_WAE, FISH_COUNT, .id = "id", .remove = T  )

KV_WAE[ , date_clean := as.IDate(SRVY_DT, format = "%m/%d/%Y") ,]

KV_WAE[ , .N , .(catch = !is.na(CPUE), length = !is.na(LEN_MM), weight = !is.na(WT_G), age = !is.na(OFF_AGE))]
KV_WAE[ , .N , .(year = year(date_clean) , catch = !is.na(CPUE), length = !is.na(LEN_MM), age = !is.na(OFF_AGE))]



# lets explore some unmatched lengths and see if there are catch data that correspond:

wae_gn_records[is.na()]


raw_agedfish <- fread("C:\\Users\\verh0064\\Desktop\\all_aged_fish_GH_2023_nullS.txt")

raw_agedfish[ , .N , OFFICIAL_AGE ][order(OFFICIAL_AGE)]
raw_agedfish[ , .N , is.na(OFFICIAL_AGE) ]





```



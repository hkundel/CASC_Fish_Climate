---
title: "MN_Flat_File_Aggregation"
author: "Holly Kundel & Mike Verhoeven"
date: "`r Sys.Date()`"
output: html_document
---
# Preamble

libraries
```{r}
library(arrow)
library(readr)
library(dplyr)
library(stringr)
library(data.table)
library(janitor)
library(tidyr)
library(lubridate)

options(scipen = 999)
```


Update 6/7/2023 Mike: 
- uses fread() b/c arrow_read_csv() seems to be choking on the mn_fish_2022only_31May2023.csv file.
- I perused Holly's work and I think I might need to start fresh here. 

# Load Data



```{r}

files_list <- list.files(path = "E:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data", pattern = ".+\\.csv") #grabs only.csv files
files_list

n <- length(files_list)

for(i in 1:n) {
  #i = 1
  filei <- word(gsub(".csv","", files_list[i]), start = -1, sep = fixed("/"))
  #this does those two steps in one package
  assign(filei ,
          fread(paste0("E:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data/",
                                          files_list[i])))
  
  # note we want to review a sorted list of column names to check misspelling etc.
  # we still need to use the columns with names like col_name_length_in, or known_units
  
  
  cde %>% # call data explainer file
    filter(`new_file_name`== filei)%>% #keep only the row relevant to this file
    select_if(~ !any(is.na(.))) %>% 
    transpose(keep.names = "newname") %>% 
    rename("oldname" = V1) %>% 
    assign("names", ., envir = .GlobalEnv)
  
  #see if any column names will not have a match! 
  # IF any pop FALSE, force stop and revist of data explainer ()
  # - e.g., named something "total catch" when actual column name was "total_catch"
  print(
    cbind(colnames(get(filei)),
          colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
    )
  )
  
  # break the loop if the current file has column names not in the data explainer
  if (all(cbind(colnames(get(filei)),  colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ])[,2]) == FALSE ) break
  
  # append old col names into new "notes" columns:
  get(filei)[ , (names[ str_detect(newname, "notes") , oldname   ,  ]) := Map(paste, colnames(.SD), .SD, sep = ':') , .SDcols =  names[ str_detect(newname, "notes") , oldname   ,  ] ]
  
  #now rename that file's colnames
  setnames(get(filei), colnames(get(filei)), names[!str_detect(newname,"unique_row_key")] [match(names(get(filei)),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )
  
  #append all other data from data explainer
  unusedbits <- 
    data.table(
      matrix(
        rep(names[ !newname %in% colnames(get(filei)) , oldname , ],
            each = nrow(get(filei))
        ),
        nrow = nrow(get(filei)),
        dimnames = list(rep(NA,nrow(get(filei))),
                        names[ !newname %in% colnames(get(filei)) , newname , ])
        )
      )
  
  #add all not yet used columns from data explainer:
  get(filei)[ , (names[ !newname %in% colnames(get(filei)) , newname , ]) := unusedbits[] ]

  #confirm import of files:  
  print(paste(filei ,"added to workspace" ))  
  
}  

```


# Catch Merge



```{r}


catch <- rbindlist(list(rbindlist(list(mn_gde_gsh_fish_effort_03May2022,
                                    mn_fish_effort_03May2022),
                               fill = TRUE,
                               use.names = TRUE),
                     mn_cpue_2022only_31May2023),
                fill = TRUE,
                use.names = TRUE)



########## NEED to integrate the ef_lmb_smb_effortdata here ^^. That file contains no catch info (but we can calc that from the catch file)

## This highlights the idea that catch and effort are coming to our doorstep two ways: 
#1: effort data contains NO corresponding catch info (the MN EF data look like this)
#2: effort data contain some or all of the catch data (most mn efforts contain catch summaries, eg., number of individuals per species)

## As such, we need some way to steer our workflow through the parsing of those data. We need different streams for each type (in all likelihood--unless we can have a workflow that works on all types)

#fix up dates
# catch[ , as.IDate(unique(word(date.1, 1, sep = fixed(" "))), format = "%m/%d/%Y") , ]
catch[ , date_clean :=  as.IDate(word(date.1, 1, sep = fixed(" ")), format = "%m/%d/%Y"),]
catch[ is.na(date_clean), ]

catch[ , hist(yday(date_clean)) ,]
catch[ , hist(year(date_clean)) ,]

#check other fields
names(catch)

#tidy sampling methods
catch[ , unique(sampling_method), ]
#do we have abbreviated gears where missing in ^?
catch[is.na(sampling_method), unique(sampling_method_abbrev)]
#backfill the sampling_method column from codes:
catch[is.na(sampling_method) &
        sampling_method_abbrev == "GSH",
      sampling_method := "Shallow gill nets"]
catch[is.na(sampling_method) &
        sampling_method_abbrev == "GDE",
      sampling_method := "Deep gill nets"]
catch[is.na(sampling_method) &
        sampling_method_abbrev == "TN",
      sampling_method := "Standard trap nets"]
catch[is.na(sampling_method) &
        sampling_method_abbrev == "GN",
      sampling_method := "Standard gill nets"]
#ditch the abbreviation/code column
catch[ , sampling_method_abbrev := NULL, ]

#tidy up the FWB ID and verify that it is same resolution as DOW_ID
catch[ , unique(word(garbage_bin_notes.1, sep = ":")) ,]
catch[ , garbage_bin_notes.1 := paste("FISHERIES_WATERBODY_ID", word(garbage_bin_notes.1, 2, sep = ":"), sep = "_") ]
catch[ , length(unique(lake_id)) , garbage_bin_notes.1 ][V1 > 1]

names(catch)[names(catch)== "garbage_bin_notes.1"] <- "lake_id.2"

#multiple names in here for walleye?
catch[ , sort(unique(species.1)) , ] #nope. Looks ltidy enough

names(catch)

#how many walleye expected in our results?
sum(catch[ species.1 == "walleye", total_count  ,]) #529,259 individuals caught
sum(catch[ species.1 == "walleye" & 
             sampling_method != "Standard trap nets", total_count  ,]) #459,954 individuals caught in gillnets
sum(catch[ species.1 == "walleye" & 
             sampling_method != "Standard trap nets" &
             original_file_name.1 != "2023_GH_cpue.txt" , total_count  ,]) #447,056 individuals caught in gillnets w/o the 2022 data

#clean up lake_names cols
catch[ , sort(unique(lake_name.1)) ,]
catch[ , sort(unique(lake_name.2)) ,]
catch[ lake_name.2 %in% c("null", "N/A"), lake_name.2 := NA]


#ditch some garbage columns?
trash <- names(catch)[str_detect(names(catch), "garbage")]
catch[ , unique(.SD) , .SDcols = trash]
# what are those weights?
catch[str_detect(garbage_bin_notes.3, "WEIGHT")]
# these weights are associated with multiple fish, so maybe a mean or median--we're going to drop them (we can't assess anything from aggregated weights)
catch[ , `:=` (garbage_bin_notes.2 = NULL,
               garbage_bin_notes.3 = NULL,
               garbage_bin_notes.4 = NULL)]
#year
catch[ , unique(year) , ]
catch[ is.na(year), year := year(date_clean)]

#effortunits
catch[ , unique(effort_units.1) ,]
catch[effort_units.1 == "knownunit_number_of_net_nights" , , ]
catch[effort_units.1 == "knownunit_number_of_nets" , effort_units.1 := "knownunit_number_of_net_nights" , ]


#unique row key fields can be dropped
# these weights are associated with multiple fish, so maybe a mean or median--we're going to drop them (we can't assess anything from aggregated weights)
catch[ , `:=` (unique_row_key.1 = NULL,
               unique_row_key.2 = NULL,
               unique_row_key.3 = NULL,
               unique_row_key.4 = NULL)]
#drop cpue
catch[ , cpue := NULL ,]


# build into wide matrix style:

  names(catch)
setcolorder(catch, c("lake_id", "lake_id.2", "lake_name.1", "lake_name.2", "sampling_method", "date_clean", "date.1", "year", "effort_units.1", "survey_type.1", "total_effort_1.1"))
#check for unique data within a survey:
#corey geving says a survey is a combination of lake, method, date
catch[ , .N , .(lake_id, lake_id.2, sampling_method, date_clean)] #21807 surveys
catch[ , .N , .(lake_id, lake_id.2, lake_name.1, sampling_method, date_clean)] #21807 surveys
catch[ , .N , .(lake_id, lake_id.2, lake_name.1, lake_name.2, sampling_method, date_clean)] #21807 surveys
catch[ , .N , .(lake_id, lake_id.2, lake_name.1, lake_name.2, sampling_method, date_clean, date.1)] #21807 surveys
catch[ , .N , .(lake_id, lake_id.2, lake_name.1, lake_name.2, sampling_method, date_clean, date.1, year)] #21807 surveys
catch[ , .N , .(lake_id, lake_id.2, lake_name.1, lake_name.2, sampling_method, date_clean, date.1, year, effort_units.1)] #21807 surveys
catch[ , .N , .(lake_id, lake_id.2, lake_name.1, lake_name.2, sampling_method, date_clean, date.1, year, effort_units.1)] #21807 surveys
catch[ , .N , .(lake_id, lake_id.2, lake_name.1, lake_name.2, sampling_method, date_clean, date.1, year, effort_units.1, survey_type.1)] #21827 surveys when we allow survey_type to vary within a survey
catch[ , .N , .(lake_id, lake_id.2, lake_name.1, lake_name.2, sampling_method, date_clean, date.1, year, effort_units.1, survey_type.1, total_effort_1.1)]#21828 surveys when we allow unequal effort within gears (this could occur where different nets were left out for different pds of time)
catch[ , .N , .(lake_id, lake_id.2, lake_name.1, lake_name.2, sampling_method, date_clean, date.1, year, effort_units.1, survey_type.1, total_effort_1.1, survey_id)] #21830 surveys when we allow survey_type to vary within a survey

surveykeycols <- names(catch)[!(names(catch) %in% c("species.1", "cpue", "total_count"))]
catch[ , .N , surveykeycols] # 21830 surveys if all but^ included

catch[ , species.1 := paste("taxa", species.1, sep = "_")]

catch_w <- dcast(catch[] , ... ~ species.1 , value.var = "total_count", fill = 0)

catch_w[, sum(taxa_walleye)  , ]

#any surveys with nothing caught?
names(catch_w)[str_detect(names(catch_w), "taxa_")]
any(rowSums(catch_w[ , .SD , .SDcols = names(catch_w)[str_detect(names(catch_w), "taxa_")] ])==0)

catch_w[ , nothing_caught := rowSums(catch_w[ , .SD , .SDcols = names(catch_w)[str_detect(names(catch_w), "taxa_")] ])==0  ,]

catch_w[nothing_caught==T] #2 surveys really did catch NADA



#now expand to long data:

catch_expanded <- melt(catch_w, measure.vars = patterns("^taxa"), variable.name = "species", value.name = "count"  )[order(survey_id), ,]

catch_expanded[species == "taxa_walleye", sum(count)] #529259

catch_expanded_presences_only <- uncount(catch_expanded, count, .remove = F, .id = "id") # this will drop all zeros

catch_expanded[count==0, id := NA]

nrow(rbind(catch_expanded[count==0],catch_expanded_presences_only))

catch_expanded <- rbind(catch_expanded[count==0],catch_expanded_presences_only)

rm(catch_expanded_presences_only)

wae_catch <- catch_expanded[species == "taxa_walleye"]

wae_catch[ str_detect(sampling_method, "gill nets"),  ,  ]





#now tie the aged fish data to these catch records

age <- rbindlist(list(mn_aged_fish_v2_20apr2023,
                                    mn_fish_2022only_31May2023),
                               fill = TRUE,
                               use.names = TRUE)

age[ , unique(species.1) ,]
age[, .N , .(species.1, species.2)][ order(-species.1)]
#move species codes to species.2
age[is.na(species.2) , `:=` (species.2 = species.1, species.1 = NA) ]

age[!is.na(species.1) , .N , .(species.1, species.2)][ order(-species.1)]
MN_sp_key <- age[!is.na(species.1) , .N , .(species.1, species.2)][ order(-species.1)][, .(species.1, species.2), ]

#something odd happening in here:
age[is.na(species.1)]$species.1 <- MN_sp_key[match(age[is.na(species.1) , species.2],MN_sp_key[ , species.2]), species.1]

age[species.1 == "walleye"]

names(catch_expanded)
names(age)

#fix up dates
age[ , .N , .(date.1, date.2) ]
age[ , unique(date.1) ,]
age[ , date.1 := as.IDate(date.1, format = "%m/%d/%Y") ,]
age[ , date.2 := as.IDate(date.2, format = "%m/%d/%Y") ,]
#date 1 was called sample_date, and date two was called SRVY_DT. 
age[ !(date.1 == date.2), summary(date.1 - date.2) ]
age[ !(date.1 == date.2), hist(date.1 - date.2) ]
# we will use "survey date"
age[, date_clean :=  as.IDate(date.1)]
age[ , hist(yday(date_clean))]

# make other dates character strings
# datecols <- colnames(age)[str_detect(colnames(age), "date\\.")]
# age[    , (datecols) := lapply(.SD, as.character)    ,   .SDcols = datecols]

#fix up methods
age[ , unique(sampling_method_abbrev) , ]
age[ , .N , sampling_method_abbrev]
age[sampling_method_abbrev == "GDE" , sampling_method := "Deep gill nets"]  
age[sampling_method_abbrev == "GSH", sampling_method := "Shallow gill nets"] 
age[sampling_method_abbrev == "GN", sampling_method := "Standard gill nets" ]
age[sampling_method_abbrev == "TN", sampling_method :=  "Standard trap nets"]

age[ , .N ,species.1]
names(age)[names(age)=="species.1"] <- "species"

#id to the aged fish
age[ , id := seq_len(.N) , .(lake_id, date_clean, sampling_method, species) ]
age[ , summary(id) ,]



catch_expanded[ , species:= gsub("taxa_", "", species) ,]

# age data cleaning
cols <- c("lake_id", "date_clean", "sampling_method", "id", "species",
          "state", "county", "lake_name.1",  "survey_id", "site_id.1" ,  #loc dat
          "date.1", "date.2", #date dat
          "age", "length.1", "length_unit.1", "species.2", #core fish dat
          "aging_structure", "sex", "weight.1", "weight_unit.1",  "young_of_year"  #extra useful bits
)
setcolorder(age,c(cols))

colnames(age)
colnames(catch_expanded)



#scope the merge:
#87% of the wb in the aged fish are in the catch data
sum(age[ , .N , lake_id][,lake_id] %in% catch_expanded[ , unique(lake_id)])/age[, length(unique(lake_id)) ,] 

#20% coverage on the survey id column--this checks. Corey Geving said to stay away from these
sum(age[ , .N , survey_id][,survey_id] %in% catch_expanded[ , unique(survey_id)])/age[, length(unique(survey_id)) ,] 

#49% coverage on the survey id column--this checks. Corey Geving said to stay away from these
sum(age[ , .N , date_clean][,date_clean] %in% catch_expanded[ , unique(date_clean)])/age[, length(unique(date_clean)) ,] 

#we know that dates are a problem, can we schmooze that join?
# flatfish <- merge(catch_expanded,age, by = c("lake_id", "date_clean" , "sampling_method", "id", "species"), suffixes = c("_catch", "_age"))

flatfish <- merge(catch_expanded,age, by = c("lake_id", "date_clean" , "sampling_method", "id", "species"), suffixes = c("_catch", "_age"), all = T)

flatfish[ , .N , is.na(state_age)]



#clearing memory to free up space:

rm(catch, catch_w, wae_catch, unusedbits, names, mn_gde_gsh_fish_effort_03May2022, mn_fish_effort_03May2022, mn_cpue_2022only_31May2023, mn_ef_lmb_smb_catch_26Aug2022, mn_ef_lmb_smb_effort_26Aug2022, cde)

flatfish[ species == "walleye" , .N ,]

wae_gn_records <- flatfish[ species == "walleye" & 
                              str_detect(sampling_method, "gill nets"),,]

wae_gn_records[ , .N , .(effort_dat= !is.na(count), age_dat = !is.na(age), length_dat = !is.na(length.1))]


age[species == "walleye" , .N  , ]


rm(a)

age[lake_id == 38055200 & date_clean == "2010-6-21" & species == "walleye"]


#save to disk:

# saveRDS(wae_gn_records, file = "Data_and_Scripts\\Data\\output\\wae_gn_mn.rds")
# 
# saveRDS(flatfish, file = "Data_and_Scripts\\Data\\output\\mn_flat_catch_age_merge.rds")
# 



```


```{r}
# review what's available for WAE data, esp to compare to kelsey V's work:

wae_gn_records[ year(date_clean)%in% c(2018:2022)  , .N , .(year(date_clean), cpue = !is.na(count) ,length = !is.na(length.1), age = !is.na(age)) ][order(year)]



mn_fish_2022only_31May2023[ , .N , .(length = !is.na(length.1), age = !is.na(age) )  ]

KV_WAE <- fread("C:\\Users\\verh0064\\Desktop\\2019_WAE_RAW_ALLREGIONS_20200505.csv")

colnames(KV_WAE)
KV_WAE[ , .N , as.integer(FISH_COUNT)]

KV_WAE[ , FISH_COUNT := as.integer(FISH_COUNT) ,]

KV_WAE <-  uncount(KV_WAE, FISH_COUNT, .id = "id", .remove = T  )

KV_WAE[ , date_clean := as.IDate(SRVY_DT, format = "%m/%d/%Y") ,]

KV_WAE[ , .N , .(catch = !is.na(CPUE), length = !is.na(LEN_MM), weight = !is.na(WT_G), age = !is.na(OFF_AGE))]
KV_WAE[ , .N , .(year = year(date_clean) , catch = !is.na(CPUE), length = !is.na(LEN_MM), age = !is.na(OFF_AGE))]



# lets explore some unmatched lengths and see if there are catch data that correspond:

wae_gn_records[is.na()]


raw_agedfish <- fread("C:\\Users\\verh0064\\Desktop\\all_aged_fish_GH_2023_nullS.txt")

raw_agedfish[ , .N , OFFICIAL_AGE ][order(OFFICIAL_AGE)]
raw_agedfish[ , .N , is.na(OFFICIAL_AGE) ]





```



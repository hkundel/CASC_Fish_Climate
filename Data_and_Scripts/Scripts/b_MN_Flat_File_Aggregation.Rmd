---
title: "MN_Flat_File_Aggregation"
author: "Holly Kundel & Mike Verhoeven"
date: "`r Sys.Date()`"
output: html_document
---
# Preamble

libraries
```{r}
library(arrow)
library(readr)
library(dplyr)
library(stringr)
library(data.table)
library(janitor)
library(tidyr)
library(lubridate)

options(scipen = 999)
```

Update 13 June 2023 Mike: 
- We've got new indiv fish data, so we'll connect to that in building our "flat file"
- mn_fish_2022only_31May2023.csv file has issues (e.g., doesn't include any un-aged fish)
- mn_cpue_2022only_31May2023.csv file has issues (e.g., doesn't include any un-aged fish)
- our goal today is a functional mn flat file

Update 7 June 2023 Mike: 
- uses fread() b/c arrow_read_csv() seems to be choking on the mn_fish_2022only_31May2023.csv file.
- I perused Holly's work and I think I might need to start fresh here. 



# Load Data



```{r}

files_list <- list.files(path = "E:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data", pattern = ".+\\.csv") #grabs only.csv files
files_list

#manually drop that 2022 fish
files_list <- files_list[!(files_list %in% c("mn_cpue_2022only_31May2023.csv", "mn_fish_2022only_31May2023.csv"))]



n <- length(files_list)

for(i in 1:n) {
  #i = 1
  filei <- word(gsub(".csv","", files_list[i]), start = -1, sep = fixed("/"))
  #this does those two steps in one package
  assign(filei ,
          fread(paste0("E:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data/",
                                          files_list[i])))
  
  # note we want to review a sorted list of column names to check misspelling etc.
  # we still need to use the columns with names like col_name_length_in, or known_units
  
  
  cde %>% # call data explainer file
    filter(`new_file_name`== filei)%>% #keep only the row relevant to this file
    select_if(~ !any(is.na(.))) %>% 
    transpose(keep.names = "newname") %>% 
    rename("oldname" = V1) %>% 
    assign("names", ., envir = .GlobalEnv)
  
  #see if any column names will not have a match! 
  # IF any pop FALSE, force stop and revist of data explainer ()
  # - e.g., named something "total catch" when actual column name was "total_catch"
  print(
    cbind(colnames(get(filei)),
          colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
    )
  )
  
  # break the loop if the current file has column names not in the data explainer
  if (all(cbind(colnames(get(filei)),  colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ])[,2]) == FALSE ) break
  
  # append old col names into new "notes" columns:
  get(filei)[ , (names[ str_detect(newname, "notes") , oldname   ,  ]) := Map(paste, colnames(.SD), .SD, sep = ':') , .SDcols =  names[ str_detect(newname, "notes") , oldname   ,  ] ]
  
  #now rename that file's colnames
  setnames(get(filei), colnames(get(filei)), names[!str_detect(newname,"unique_row_key")] [match(names(get(filei)),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )
  
  #append all other data from data explainer
  unusedbits <- 
    data.table(
      matrix(
        rep(names[ !newname %in% colnames(get(filei)) , oldname , ],
            each = nrow(get(filei))
        ),
        nrow = nrow(get(filei)),
        dimnames = list(rep(NA,nrow(get(filei))),
                        names[ !newname %in% colnames(get(filei)) , newname , ])
        )
      )
  
  #add all not yet used columns from data explainer:
  get(filei)[ , (names[ !newname %in% colnames(get(filei)) , newname , ]) := unusedbits[] ]

  #confirm import of files:  
  print(paste(filei ,"added to workspace" ))  
  
} 

# check warnings and see if we can make it go away
#print some kind of completion confirmation?

```


# Catch Merge



```{r}

# this rbind puts together 3 files that are not equivalent (ef data is true effort data (each row is gear in a survey) and the other 2 are catch files (each row is a species in a a gear in a survey))
#create an issue for this idea
## This highlights the idea that catch and effort are coming to our doorstep two ways: 
#1: effort data contains NO corresponding catch info (the MN EF data look like this)
#2: effort data contain some or all of the catch data (most mn efforts contain catch summaries, eg., number of individuals per species)

## As such, we need some way to steer our workflow through the parsing of those data. We need different streams for each type (in all likelihood--unless we can have a workflow that works on all types)
effort <- rbindlist(list(rbindlist(list(mn_gde_gsh_fish_effort_03May2022,
                                    mn_fish_effort_03May2022),
                               fill = TRUE,
                               use.names = TRUE),
                     mn_ef_lmb_smb_effort_26Aug2022),
                fill = TRUE,
                use.names = TRUE)

#make all into effort files
# we want to match the same data per row format as the EF effort data. We can see (after some sleuthing) that that dataset has a unique key in the combo of (lake_id, date.2(survey date), gear, survey type)
mn_ef_lmb_smb_effort_26Aug2022[ ,  .N , .(lake_id, date.2, sampling_method_abbrev, survey_type.1)] #here date.2 is the survey date
mn_gde_gsh_fish_effort_03May2022[ , .N , .(lake_id, date.1, sampling_method_abbrev, survey_type.1) ] #here date.1 is the survey date
mn_fish_effort_03May2022[          , .N , .(lake_id, date.1, sampling_method_abbrev, survey_type.1) ]

#drop cpue
## create an issue for this idea
  #general gears
  mn_fish_effort_03May2022[ , cpue , ]
  mn_fish_effort_03May2022[ , round(total_count/total_effort_1.1,2) , ]
  sum(!mn_fish_effort_03May2022[ , cpue == round(total_count/total_effort_1.1,2) , ])# the number of cases where DNR calcd CPUE does not == catch/effort
  
  #this is odd, suggests something wonky w/ dnr measured cpues
  mn_fish_effort_03May2022[ , cpue := NULL ,]
  
  #deep and shallow Gns
  sum(!mn_gde_gsh_fish_effort_03May2022[ , cpue == round(total_count/total_effort_1.1,2) , ])# the number of cases where DNR calcd CPUE does not == catch/effort
  ## create an issue for this idea
  #this is odd, suggests something wonky w/ dnr measured cpues
  mn_gde_gsh_fish_effort_03May2022[ , cpue := NULL ,]

  #tag the species for easy col selection:
  mn_gde_gsh_fish_effort_03May2022[ , species.1 := paste("taxa", species.1, sep = "_")]
  mn_fish_effort_03May2022[ , species.1 := paste("taxa", species.1, sep = "_")]

# species, total count and cpue are only species specific components (cpue has been dropped)
mn_fish_effort_03May2022 <- dcast(mn_fish_effort_03May2022 , ... ~ species.1 , value.var = "total_count", fill = 0)
mn_gde_gsh_fish_effort_03May2022 <- dcast(mn_gde_gsh_fish_effort_03May2022 , ... ~ species.1 , value.var = "total_count", fill = 0)


# this rbind puts together 3 files that should now be equivalent (each row is gear in a survey)
effort <- rbindlist(list(rbindlist(list(mn_gde_gsh_fish_effort_03May2022,
                                    mn_fish_effort_03May2022),
                               fill = TRUE,
                               use.names = TRUE),
                     mn_ef_lmb_smb_effort_26Aug2022),
                fill = TRUE,
                use.names = TRUE)



#fix up dates
# catch[ , as.IDate(unique(word(date.1, 1, sep = fixed(" "))), format = "%m/%d/%Y") , ]
effort[ , date_clean :=  as.IDate(word(date.1, 1, sep = fixed(" ")), format = "%m/%d/%Y"),]
effort[ is.na(date_clean), ]

effort[ , hist(yday(date_clean)) ,]
effort[ , hist(year(date_clean)) ,]

#check other fields
names(effort)

#move no-taxa to the left
colnames(effort)[!str_detect(colnames(effort), "taxa_")]
setcolorder(effort, colnames(effort)[!str_detect(colnames(effort), "taxa_")])

#tidy sampling methods
effort[ , .N , sampling_method ]
effort[ , .N , .(sampling_method_abbrev)]
#do we have abbreviated gears where missing in ^?
effort[is.na(sampling_method), unique(sampling_method_abbrev)]

#backfill the sampling_method column from codes:
effort[is.na(sampling_method) &
        sampling_method_abbrev == "GSH",
      sampling_method := "Shallow gill nets"]
effort[is.na(sampling_method) &
        sampling_method_abbrev == "GDE",
      sampling_method := "Deep gill nets"]
effort[is.na(sampling_method) &
        sampling_method_abbrev == "TN",
      sampling_method := "Standard trap nets"]
effort[is.na(sampling_method) &
        sampling_method_abbrev == "GN",
      sampling_method := "Standard gill nets"]

#ditch the abbreviation/code column
effort[ , sampling_method_abbrev := NULL, ]

#tidy up the FWB ID and verify that it is same resolution as DOW_ID
effort[ , unique(word(garbage_bin_notes.1, sep = ":")) ,]
effort[word(garbage_bin_notes.1, sep = ":")=="FISHERIES_WATERBODY_ID" , .N ]
effort[ word(garbage_bin_notes.1, sep = ":")=="FISHERIES_WATERBODY_ID"  , length(unique(lake_id)) , garbage_bin_notes.1 ][V1 > 1]
effort[word(garbage_bin_notes.1, sep = ":")=="FISHERIES_WATERBODY_ID", "lake_id.2" := garbage_bin_notes.1 , ]
effort[word(garbage_bin_notes.1, sep = ":")=="FISHERIES_WATERBODY_ID", garbage_bin_notes.1 := NA , ]



sort(names(effort))

#how many walleye expected in our results?
sum(effort[ , taxa_walleye , ], na.rm = T)


#year
effort[ , unique(year) , ]
effort[ is.na(year),]
 sum(effort[ ,year != year(date_clean)])
##consider adding this as an issue, could sleuth around the dates and see if other date cols match better, try DT[ , hist(year-year(date.1))]

#effortunits
effort[ , unique(effort_units.1) ,]
effort[effort_units.1 == "knownunit_number_of_nets" , effort_units.1 := "knownunit_number_of_net_nights" , ]


#unique row key fields can be dropped
# these weights are associated with multiple fish, so maybe a mean or median--we're going to drop them (we can't assess anything from aggregated weights)
effort[ , `:=` (unique_row_key.1 = NULL,
               unique_row_key.2 = NULL,
               unique_row_key.3 = NULL,
               unique_row_key.4 = NULL)]



#any surveys with nothing caught?
names(effort)[str_detect(names(effort), "taxa_")]
any(rowSums(effort[ , .SD , .SDcols = names(effort)[str_detect(names(effort), "taxa_")] ], na.rm =T)==0)

effort[ , .N , new_file_name]

nrow(effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022"][rowSums(effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022", .SD , .SDcols = names(effort)[str_detect(names(effort), "taxa_")] ], na.rm = T)==0])

#in order to calc a nothign caught column, lets fill NAs with zeros in the non-EF data

effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022", .SD , .SDcols = names(effort)[str_detect(names(effort), "taxa_")]]

effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022", setnafill(.SD, fill = 0) , .SDcols = names(effort)[str_detect(names(effort), "taxa_")]]

effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022", .SD , .SDcols = colnames(effort)[str_detect(names(effort), "taxa_")]]

setnafill(effort, fill = 0, cols = colnames(effort)[str_detect(names(effort), "taxa_")] )
effort[new_file_name != "mn_ef_lmb_smb_effort_26Aug2022", .SD , .SDcols = names(effort)[str_detect(names(effort), "taxa_")]]

#ef data now have zero catches in the taxa_cols
effort[new_file_name == "mn_ef_lmb_smb_effort_26Aug2022", names(effort)[str_detect(names(effort), "taxa_")] := NA , ]
effort[new_file_name == "mn_ef_lmb_smb_effort_26Aug2022", .SD , .SDcols = names(effort)[str_detect(names(effort), "taxa_")] ]


effort[ , nothing_caught := rowSums(catch_w[ , .SD , .SDcols = names(catch_w)[str_detect(names(catch_w), "taxa_")] ])==0  ,]



catch_w[nothing_caught==T] #2 surveys really did catch NADA



#now expand to long data:

catch_expanded <- melt(catch_w, measure.vars = patterns("^taxa"), variable.name = "species", value.name = "count"  )[order(survey_id), ,]

catch_expanded[species == "taxa_walleye", sum(count)] #529259

catch_expanded_presences_only <- uncount(catch_expanded, count, .remove = F, .id = "id") # this will drop all zeros

catch_expanded[count==0, id := NA]

nrow(rbind(catch_expanded[count==0],catch_expanded_presences_only))

catch_expanded <- rbind(catch_expanded[count==0],catch_expanded_presences_only)

rm(catch_expanded_presences_only)

wae_catch <- catch_expanded[species == "taxa_walleye"]

wae_catch[ str_detect(sampling_method, "gill nets"),  ,  ]





#now tie the aged fish data to these catch records

age <- rbindlist(list(mn_aged_fish_v2_20apr2023,
                                    mn_fish_2022only_31May2023),
                               fill = TRUE,
                               use.names = TRUE)

age[ , unique(species.1) ,]
age[, .N , .(species.1, species.2)][ order(-species.1)]
#move species codes to species.2
age[is.na(species.2) , `:=` (species.2 = species.1, species.1 = NA) ]

age[!is.na(species.1) , .N , .(species.1, species.2)][ order(-species.1)]
MN_sp_key <- age[!is.na(species.1) , .N , .(species.1, species.2)][ order(-species.1)][, .(species.1, species.2), ]

#something odd happening in here:
age[is.na(species.1)]$species.1 <- MN_sp_key[match(age[is.na(species.1) , species.2],MN_sp_key[ , species.2]), species.1]

age[species.1 == "walleye"]

names(catch_expanded)
names(age)

#fix up dates
age[ , .N , .(date.1, date.2) ]
age[ , unique(date.1) ,]
age[ , date.1 := as.IDate(date.1, format = "%m/%d/%Y") ,]
age[ , date.2 := as.IDate(date.2, format = "%m/%d/%Y") ,]
#date 1 was called sample_date, and date two was called SRVY_DT. 
age[ !(date.1 == date.2), summary(date.1 - date.2) ]
age[ !(date.1 == date.2), hist(date.1 - date.2) ]
# we will use "survey date"
age[, date_clean :=  as.IDate(date.1)]
age[ , hist(yday(date_clean))]

# make other dates character strings
# datecols <- colnames(age)[str_detect(colnames(age), "date\\.")]
# age[    , (datecols) := lapply(.SD, as.character)    ,   .SDcols = datecols]

#fix up methods
age[ , unique(sampling_method_abbrev) , ]
age[ , .N , sampling_method_abbrev]
age[sampling_method_abbrev == "GDE" , sampling_method := "Deep gill nets"]  
age[sampling_method_abbrev == "GSH", sampling_method := "Shallow gill nets"] 
age[sampling_method_abbrev == "GN", sampling_method := "Standard gill nets" ]
age[sampling_method_abbrev == "TN", sampling_method :=  "Standard trap nets"]

age[ , .N ,species.1]
names(age)[names(age)=="species.1"] <- "species"

#id to the aged fish
age[ , id := seq_len(.N) , .(lake_id, date_clean, sampling_method, species) ]
age[ , summary(id) ,]



catch_expanded[ , species:= gsub("taxa_", "", species) ,]

# age data cleaning
cols <- c("lake_id", "date_clean", "sampling_method", "id", "species",
          "state", "county", "lake_name.1",  "survey_id", "site_id.1" ,  #loc dat
          "date.1", "date.2", #date dat
          "age", "length.1", "length_unit.1", "species.2", #core fish dat
          "aging_structure", "sex", "weight.1", "weight_unit.1",  "young_of_year"  #extra useful bits
)
setcolorder(age,c(cols))

colnames(age)
colnames(catch_expanded)



#scope the merge:
#87% of the wb in the aged fish are in the catch data
sum(age[ , .N , lake_id][,lake_id] %in% catch_expanded[ , unique(lake_id)])/age[, length(unique(lake_id)) ,] 

#20% coverage on the survey id column--this checks. Corey Geving said to stay away from these
sum(age[ , .N , survey_id][,survey_id] %in% catch_expanded[ , unique(survey_id)])/age[, length(unique(survey_id)) ,] 

#49% coverage on the survey id column--this checks. Corey Geving said to stay away from these
sum(age[ , .N , date_clean][,date_clean] %in% catch_expanded[ , unique(date_clean)])/age[, length(unique(date_clean)) ,] 

#we know that dates are a problem, can we schmooze that join?
# flatfish <- merge(catch_expanded,age, by = c("lake_id", "date_clean" , "sampling_method", "id", "species"), suffixes = c("_catch", "_age"))

flatfish <- merge(catch_expanded,age, by = c("lake_id", "date_clean" , "sampling_method", "id", "species"), suffixes = c("_catch", "_age"), all = T)

flatfish[ , .N , is.na(state_age)]



#clearing memory to free up space:

rm(catch, catch_w, wae_catch, unusedbits, names, mn_gde_gsh_fish_effort_03May2022, mn_fish_effort_03May2022, mn_cpue_2022only_31May2023, mn_ef_lmb_smb_catch_26Aug2022, mn_ef_lmb_smb_effort_26Aug2022, cde)

flatfish[ species == "walleye" , .N ,]

wae_gn_records <- flatfish[ species == "walleye" & 
                              str_detect(sampling_method, "gill nets"),,]

wae_gn_records[ , .N , .(effort_dat= !is.na(count), age_dat = !is.na(age), length_dat = !is.na(length.1))]


age[species == "walleye" , .N  , ]


rm(a)

age[lake_id == 38055200 & date_clean == "2010-6-21" & species == "walleye"]


#save to disk:

# saveRDS(wae_gn_records, file = "Data_and_Scripts\\Data\\output\\wae_gn_mn.rds")
# 
# saveRDS(flatfish, file = "Data_and_Scripts\\Data\\output\\mn_flat_catch_age_merge.rds")
# 



```


```{r}
# review what's available for WAE data, esp to compare to kelsey V's work:

wae_gn_records[ year(date_clean)%in% c(2018:2022)  , .N , .(year(date_clean), cpue = !is.na(count) ,length = !is.na(length.1), age = !is.na(age)) ][order(year)]



mn_fish_2022only_31May2023[ , .N , .(length = !is.na(length.1), age = !is.na(age) )  ]

KV_WAE <- fread("C:\\Users\\verh0064\\Desktop\\2019_WAE_RAW_ALLREGIONS_20200505.csv")

colnames(KV_WAE)
KV_WAE[ , .N , as.integer(FISH_COUNT)]

KV_WAE[ , FISH_COUNT := as.integer(FISH_COUNT) ,]

KV_WAE <-  uncount(KV_WAE, FISH_COUNT, .id = "id", .remove = T  )

KV_WAE[ , date_clean := as.IDate(SRVY_DT, format = "%m/%d/%Y") ,]

KV_WAE[ , .N , .(catch = !is.na(CPUE), length = !is.na(LEN_MM), weight = !is.na(WT_G), age = !is.na(OFF_AGE))]
KV_WAE[ , .N , .(year = year(date_clean) , catch = !is.na(CPUE), length = !is.na(LEN_MM), age = !is.na(OFF_AGE))]



# lets explore some unmatched lengths and see if there are catch data that correspond:

wae_gn_records[is.na()]


raw_agedfish <- fread("C:\\Users\\verh0064\\Desktop\\all_aged_fish_GH_2023_nullS.txt")

raw_agedfish[ , .N , OFFICIAL_AGE ][order(OFFICIAL_AGE)]
raw_agedfish[ , .N , is.na(OFFICIAL_AGE) ]





```



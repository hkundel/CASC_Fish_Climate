---
title: "IN_Flat_File_Aggregation"
author: "Mike Verhoeven"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---
# Preamble

##Instructions
This code is written in chunks that each accomplish a task moving towards the goal of a file for each state that encompasses all fish observations made/shared with us. The structure of that observation-level data should be one row per individual fish. By joining these data to the effort info, we will be able to filter and aggregate the data in flexible ways, always bringing along info on how much effort it took to catch each the fish obs (or set of fish).

The data explainer sticks .n suffixes on columns where multiple fields from one of the datasets has multiple cols that match that field (i.e., date.1, date.2, date.3). The naming conventions for cols uses "_" and no spaces.

After loading packages, the data from each state will be loaded into the WS and renamed according to the mapping of old colnames to new colnames in the data explainer. Next, the files should be explored a bit, and the script should identify files that will not be used, but instead get removed from the workspace. After this initial exploration of what's there, the files should be restructured and munged into the obs-level format described above. When this is done, subsequent blocks should conduct some baseline additional QC to verify the product of the munging is as-expected. Finally, the script should tidy up an remaining column or field formatting (e.g., species uses common names, no spaces, but "_"), and drop any unneeded columns. 


A basic guide to columns we expect to see in a observation level data are as follows:

LOCATION INFORMATION:
state - 
county - county associate with the wb in the state data
lake_name - common lang name of the lake
lake_id - usually a local id specific to the state contributing the data
nhdhr.id - This column is usually added towards the end of the script based on state lake_ids using the mwlaxeref (Paul Frater) package from here: https://drive.google.com/drive/u/1/folders/1HURmPTtufVzI0aqn7D8MpKdL5B8atCL5

SURVEY INFORMATION:
date_clean - usually multiple dates are submitted with each fish (e.g., collection date, survey end date). Use the date of the survey as the primary date for each fish observation, generating a date_clean column
survey_type - this is often specified in the data, and sometimes helps to filter out which data are useful for any given purpose (e.g., research survey, fishkill check)
survey_id - in some states this is a provided variable used as a key to each "survey." Ususally a "survey" is multiple gears on a single lake on a single date (often surveys might run multiple consecutive dates, but only one date is reported )
sampling_method - This is a gear field, and often includes wide ranging gears and sometimes very specific gears
total_effort.1 - This should be a numeric field with only the qty of effort
effort_units.1 - paired with total_effort.1, defines units for numeric
nothing_caught - specifies that nothing was caught in this effort (species will also be NA)
target_species - what was the species being targeted in the survey?
effort_ident - This is a field we add, it is a unique key for each effort unit that we have data for(usually a gear within a survey). For example, a data user could get cpue by counting all fish within a group_by(effort_id) or it's equivalent group_by(lake_id, date, survey_type,sampling_method) 

TAXA INFORMATION: 
species.1 - species common name
species_abbrev - State level code sometimes used in data share
length.1 - length of fish observed, numeric
length_unit.1 - units for length.1, also specify resolution if needed (e.g, cm, whole cm)
weight.1 - weight of fish obs, numeric
weight_unit.1 - units of weight.1, also specify resolution if needed (e.g, lb, whole lb)
sample_id.1 - unique id for each fish observation sometimes provided and sometimes useful for connecting to aged fish
age - age in years, numeric
aging_structure - what was used to determine age?
young_of_year - was the fish a YOY (i.e. hatched <365d before surveyed)
sex - sex of fish (male, female, unknown, NA)

SOURCE FILE INFORMATION: These columns come in with each dataset from the data explainer and we leave them in the product so that we could hunt down issues we find a bit more easily. 

original_file_name.1_effort - name of effort file that was used to generate data in this row
original_file_name.1_indivfish - name of individual fish file that was used to generate data in this row
original_file_name.1_[...]

FLAGS AND ISSUES:
flag - this column contains a character string with issues describing each row, each issue separated with a comma. Use mutate(flag = paste(flag, "new issue description", sep = ",")) to add to this column without overwriting other issues already specified.


# Issues to deal with
- Holly is working on glacial lakes
- IN glacial lakes needs to use new file from Matthew Linn (11/16/23)
- Get age data from Matthew Linn for the IN glacial lakes

- reservior update (Denver 11/21)
  -community surveys mostly done 
   - survey 273 has effort data but is not in the catch
  -select columns to carry through

- Can glacial lakes and reservoirs be filtered the same way? Or do they need different filtering mechanisms








##Libraries
```{r}
library(arrow)
library(readr)
library(dplyr)
library(stringr)
library(data.table)
library(janitor)
library(tidyr)
library(lubridate)
library(bit64)

options(scipen = 999)
```


##Data
This could readily be changed into a function that takes a filepath and returns files into environment.
* note Holly has to change file paths to "G" 
```{r}
#generate a file list to import
files_list <- list.files(path = "G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/IN_Data/in_raw_disaggregated_data", pattern = ".+\\.csv") #grabs only.csv files
files_list



#object for use in loop (simple length of file list)
n <- length(files_list)

for(i in 1:n) {
  #i = 1
  filei <- word(gsub(".csv","", files_list[i]), start = -1, sep = fixed("/"))
  #this does those two steps in one package
  assign(filei ,
          fread(paste0("G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/IN_Data/in_raw_disaggregated_data/",
                                          files_list[i])))
  
  # if the file is a crosswalk, do not rename anything, just loop to the confirm import line
  if(str_detect(filei, "crosswalk")) {  #confirm import of files:  
    print(paste(filei ,"added to workspace" ))  
    #confirm import of files:  
    print(paste(i ,"files added to workspace" )) ; next}
  
  #if the file is not in the data explainer, don't try to rename it:
  if(filei %in% cde$new_file_name) {
    print("renaming with data explainer")
  } else {next}
  
  
  
  
  
  # note we want to review a sorted list of column names to check misspelling etc.
  # we still need to use the columns with names like col_name_length_in, or known_units
  
  
  cde %>% # call data explainer file
    filter(`new_file_name`== filei)%>% #keep only the row relevant to this file
    select_if(~ !any(is.na(.))) %>% 
    transpose(keep.names = "newname") %>% 
    rename("oldname" = V1) %>% 
    assign("names", ., envir = .GlobalEnv)
  
  #see if any column names will not have a match! 
  # IF any pop FALSE, force stop and revisit of data explainer ()
  # - e.g., named something "total catch" when actual column name was "total_catch"
  print(
    cbind(colnames(get(filei)),
          colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
    )
  )
  
  
  # break the loop if the current file has column names not in the data explainer
  # if (all(cbind(colnames(get(filei)),  colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ])[,2]) == FALSE ) break
  if (all(colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]) == FALSE ) break
  
  
  # append old col names into new "notes" columns:
  get(filei)[ , (names[ str_detect(newname, "notes") , oldname   ,  ]) := Map(paste, colnames(.SD), .SD, sep = ':') , .SDcols =  names[ str_detect(newname, "notes") , oldname   ,  ] ]
  
  #now rename that file's colnames
  setnames(get(filei), colnames(get(filei)), names[!str_detect(newname,"unique_row_key")] [match(names(get(filei)),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )
  
  #append all other data from data explainer
  unusedbits <- 
    data.table(
      matrix(
        rep(names[ !newname %in% colnames(get(filei)) , oldname , ],
            each = nrow(get(filei))
        ),
        nrow = nrow(get(filei)),
        dimnames = list(rep(NA,nrow(get(filei))),
                        names[ !newname %in% colnames(get(filei)) , newname , ])
        )
      )
  
  #add all not yet used columns from data explainer:
  get(filei)[ , (names[ !newname %in% colnames(get(filei)) , newname , ]) := unusedbits[] ]

  #confirm import of files:  
  print(paste(filei ,"added to workspace" ))  
  #confirm import of files:  
  print(paste(i ,"files added to workspace" )) 

  
} 
  #confirm import of files:  
  print(paste(i ,"files added to workspace" ))
  #confirm import of files:  
  print(paste(n-i ,"remaining to be added" )) 



```


#Data Review
   - Holly has to re-do this with new data
      - Got new files for targeted surveys that now have a survey date associated with individual fish lengths
      - Got updated information on lake IDs and lake names, and updated the lake list files to reflect that information
   
```{r}

# review each dataset that we have, strategizing about how you'll use them to develop a obs-level file
# consider things like species scope (do I need to restrict all input data to just the 8ish game species?), file organization (is this file already in a obs-level format or is it a count of each species/size that I should uncount()?), linking keys (is there a fish obs ID in the age data that I can use to link to the fish observations data?), and what things (possibly whole datasets) are unneeded for our work, here. I have left the Michigan work in here to give you an idea of what I did:

# for IN, there are data from "glacial lakes" and there are data from "reservoirs" so will work with glacial lakes, then work with reservoirs, and then combine glacial lakes and reservoirs to make a single IN file

#effort:
  #mi_statustrends_effort_16Mar2021[ , .N , .(lake_id, lake_name.1, date.1 , survey_type.1, sampling_method_abbrev)  ]



#write out the counties in all lowercase
#in_glaciallakes_effort_6Oct2021[ , county:= str_to_lower(county)]
in_lake_id_list_1Dec2023[ , county:= str_to_title(county)]

#re-check
in_glaciallakes_effort_6Oct2021[ , .N, .(lake_name.1, county)] #129 unique lakes

#link glacial lakes effort to lake ID
  #in_glaciallakes_effort_6Oct2021[in_lake_id_list_22Aug2022, on=.(lake_name.1, county), nomatch = NULL] #doesn't work

in_lake_id_list_1Dec2023_fixed <- in_lake_id_list_1Dec2023 %>%
  mutate(county = str_to_title(county))%>%
  mutate(county_lower = str_to_lower(county))%>%
  mutate(lake_name.1 = str_remove(lake_name.1, county))%>%
  mutate(lake_name.1 = str_remove(lake_name.1, county_lower))%>%
  mutate(lake_name.1 = str_remove_all(lake_name.1, "-"))%>%
  mutate(lake_name.1 = str_replace(lake_name.1, " \\(\\)", ""))%>%
  mutate(county = str_to_lower(county))%>%
  select(lake_id, lake_name.1, county)
```

```{r}
# list used to find which names and IDs that don't work
# was used to ask Matthew Linn for clarification, Holly then updated the lake list with the information from Matthew, hence the new file
#in_GL_st_effort_no_ID <- in_glaciallakes_effort_6Oct2021 %>%
  #mutate(county = str_to_title(county))%>%
  #mutate(county_lower = str_to_lower(county))%>%
  #mutate(lake_name.1 = str_remove(lake_name.1, county))%>%
  #mutate(lake_name.1 = str_remove(lake_name.1, county_lower))%>%
  #mutate(lake_name.1 = str_remove_all(lake_name.1, "-"))%>%
  #mutate(lake_name.1 = str_replace(lake_name.1, " \\(\\)", ""))%>%
  #left_join(in_lake_id_list_22Aug2022_fixed, by = c("lake_name.1", "county"))%>%
  #filter(is.na(lake_id))%>%
  #select(lake_name.1, county)%>%
  #distinct()


#write_csv(in_lake_id_list_22Aug2022_fixed, "in_lake_id_list_22Aug2022_cleaned.csv")
#write_csv(in_GL_st_effort_no_ID, "in_GL_st_effort_no_ID.csv")
```


Data review continued

IN Glacial Lakes
```{r}
in_glaciallakes_effort_6Oct2021[ , .N, .(sampling_method)]
# Three gears: standard trap net, experimental gill net and nighttime electrofishing
  # each gear is used in every survey. 152 surveys times 3 = 456

```

From Matthew Linn IN Glacial lakes contact: "we do the same effort for each survey (2 overnight trap lifts, 2 overnight experiment gill net lifts, and 0.5 hours of nighttime electrofishing)" - this is for standard surveys

IN GL (glacial lakes)
unify effort units into a single column
```{r}
in_glaciallakes_effort_6Oct2021_2 <- in_glaciallakes_effort_6Oct2021 %>%
  mutate(effort_units = case_when(sampling_method == "Standard Trap Net" ~ "overnight lifts",
                                  sampling_method == "Experimental Gill Net" ~ "overnight lifts",
                                  sampling_method == "Nighttime Electrofishing" ~ "hours")) %>%
  select(-effort_units.1, -effort_units.2, -effort_units.3)%>% #remove these columns now that the info exists in "effort_units"
  mutate(sampling_method = str_to_lower(sampling_method))%>% #make sampling method consistent for std and targeted
  mutate(county = str_to_lower(county))%>%
  rename(effort_units.1 = effort_units)%>%
  relocate(lake_name.1, county, year, sampling_method, total_effort_1, effort_units.1)%>%
  mutate(targeted_or_standard = "standard")


in_effort_prob_list <- in_glaciallakes_effort_6Oct2021_2 %>%
  left_join(in_lake_id_list_1Dec2023_fixed, by = c("lake_name.1", "county"))%>%
  select(lake_id, lake_name.1, county, year)%>%
  distinct()
  
```

prep IN GL fish data
- already one fish per row! yay!

```{r}
#will need to clean up lake names and county names for merge

in_glaciallakes_fish_6Oct2021_2 <- in_glaciallakes_fish_6Oct2021 %>%
  rename(sampling_method_abbrev = sampling_method)%>% #this is an abbreviated name, make column with full name
  mutate(sampling_method = case_when(sampling_method_abbrev == "TN"~ "standard trap net",
                                  sampling_method_abbrev == "GN" ~ "experimental gill net",
                                  sampling_method_abbrev == "EF" ~ "nighttime electrofishing",
                                  .default = NA))%>%
  mutate(county = str_to_lower(county))%>%
  mutate(sampling_method_abbrev = if_else(sampling_method == "unknown", NA, sampling_method_abbrev))%>%
  relocate(lake_name.1, county, year, species.1, length.1, sampling_method, sampling_method_abbrev, targeted_or_standard)



in_fish_prob_list <- in_glaciallakes_fish_6Oct2021_2 %>%
  select(lake_name.1, county, year)%>%
  distinct()%>%
  left_join(in_lake_id_list_1Dec2023_fixed, by = c("lake_name.1", "county"))
```

example for Matthew Linn about mismatched counties
- will continue to work towards a product, and will flag mismatches
```{r}
in_list <- in_effort_prob_list %>%
  full_join(in_fish_prob_list, by = c("lake_name.1", "county"), suffix = c(".effort", ".fish"))%>%
  distinct()
```
 Leaving the county mismatch for now. Still need to email Matthew, will gather thoughts next week to send to him. Thinking of just keeping one county for now and rolling with it...



Set up Temporary merge with lake ID knowing that some won't match up so that a preliminary product can be created
- Standard surveys for Glacial Lakes
```{r}
in_glaciallakes_effort_6Oct2021_3 <- in_glaciallakes_effort_6Oct2021_2 %>%
  left_join(in_lake_id_list_1Dec2023_fixed, by = c("lake_name.1", "county"))%>%
  filter(is.na(lake_id))%>%
  relocate(lake_name.1, lake_id, county, year, sampling_method, total_effort_1, effort_units.1)

in_glaciallakes_fish_6Oct2021_3 <- in_glaciallakes_fish_6Oct2021 %>%
  rename(sampling_method_abbrev = sampling_method)%>% #this is an abbreviated name, make column with full name
  mutate(sampling_method = case_when(sampling_method_abbrev == "TN"~ "standard trap net",
                                  sampling_method_abbrev == "GN" ~ "experimental gill net",
                                  sampling_method_abbrev == "EF" ~ "nighttime electrofishing",
                                  .default = NA))%>%
  mutate(county = str_to_lower(county))%>%
  mutate(sampling_method_abbrev = if_else(sampling_method == "unknown", NA, sampling_method_abbrev))%>%
  left_join(in_lake_id_list_1Dec2023_fixed, by = c("lake_name.1", "county"))%>%
  relocate(lake_name.1, lake_id, county, year, species.1, length.1, sampling_method, sampling_method_abbrev, targeted_or_standard)

## Note several fish and surveys do NOT have lake ID at this point, Matthew will have to provide info to sort this out

in_glacial_lakes_standard <- in_glaciallakes_effort_6Oct2021_3 %>%
  full_join(in_glaciallakes_fish_6Oct2021_3, by = c("lake_id", "sampling_method", "year"))

in_glacial_lakes_standard2 <- in_glaciallakes_effort_6Oct2021_3 %>%
  full_join(in_glaciallakes_fish_6Oct2021_3, by = c("lake_name.1", "county", "sampling_method", "year"))

  # check for surveys that have 0 catch
  # check for instances of duplication, if this is bad, just use earlier match and flag
  # choose one county and one lake name ifelse(if same print it, if different print effort name)
  # flag problems/mismatches
  # rename columns to match agreed upon names

```


merge IN GL standard fish with effort
- 65,927 fish obs
- 456 survey/gear -> 152 individual surveys
```{r}
# set up key columns for merge
keycols_INGL <- c("lake_name.1", "county", "year", "sampling_method")

setkeyv(in_glaciallakes_fish_6Oct2021_2, keycols_INGL)
setkeyv(in_glaciallakes_effort_6Oct2021_2, keycols_INGL)

# merge IN glacial lakes standard surveys effort and fish data
in_glaciallakes_st_merge <- merge(in_glaciallakes_fish_6Oct2021_2, in_glaciallakes_effort_6Oct2021_2, by = keycols_INGL, all = T, suffixes = c("_catch", "_effort")) #get 65,942 obs... an extra 15 obs... 
    # appears some fish don't have a sampling method... 

in_glaciallakes_st_merge_check_2 <- in_glaciallakes_st_merge %>%
  filter(lake_name.1 == "Adams")
  #filter(is.na(species.1))

#check for fish without sampling method
in_GL_fish_no_samp <- in_glaciallakes_fish_6Oct2021_2 %>%
  filter(is.na(sampling_method)) #5 fish don't have a sampling method

in_GL_fish_check <- in_glaciallakes_fish_6Oct2021_2 %>%
  filter(lake_name.1 == "Adams" & year == "2011" & species.1 == "Bluegill")

## checking for lake ID work
in_clear <- in_glaciallakes_st_merge%>%
  filter(lake_name.1 == "Clear")

in_glaciallakes_fish_no_samp_method <- in_glaciallakes_fish_6Oct2021_2 %>%
  filter(is.na(sampling_method)) #there are 5 fish without a sampling method
```

IN Glacial Lakes (GL) targeted surveys
```{r}
 #prepare data for merge

in_glaciallakes_targeted_effort_16Nov2023_2 <- in_glaciallakes_targeted_effort_16Nov2023 %>%
  mutate(effort_units = case_when(sampling_method == "Experimental gill net" ~ "overnight lifts",
                                  sampling_method == "Nighttime electrofishing" ~ "hours"))%>%
  mutate(date.1 = mdy(date.1))%>%
  mutate(year = year(date.1))%>% #make column for year to match non-targeted
  mutate(sampling_method = str_to_lower(sampling_method))%>% #make sampling method consistent for std and targeted
  rename(effort_units.1 = effort_units)%>%
  mutate(county = str_to_lower(county))%>%
  mutate(date.1 = as.character(if_else(lake_name.1 == "Golden" & year == "2017", "2017-05-03", paste(as.character(date.1)))))%>%# # has mismatched survey date and fish caught date
  mutate(date.1 = as.IDate(date.1))%>%
  relocate(lake_id, lake_name.1, county, year, sampling_method, total_effort_1, effort_units.1, date.1)

in_glaciallakes_targeted_fish_16Nov2023_2 <- in_glaciallakes_targeted_fish_16Nov2023 %>%
  mutate(date.1 = mdy(date.1))%>%
  mutate(year = year(date.1))%>%
  mutate(date.1 = as.IDate(date.1))%>%
  mutate(county = str_to_lower(county))
```


- check that lake ID >= lake_name.1 and county for key columns
```{r}
in_GL_tar_effort <- in_glaciallakes_targeted_effort_16Nov2023_2 %>%
  group_by(lake_name.1, county)%>%
  summarise(Total = n()) #46 lakes

in_GL_tar_effort2 <- in_glaciallakes_targeted_effort_16Nov2023_2 %>%
  group_by(lake_id)%>%
  summarise(Total = n()) #46 lakes, looks like we can use lake ID for these surveys!
```

IN GL targeted fish data
- don't have gear listed... Matthew Linn says these are targeted surveys for LMB and cisco
- got gear added to fish length data thanks to new pull from Matthew Linn 11/16/2023
```{r}
IN_GL_targeted_LMB <- in_glaciallakes_targeted_fish_1Sep2022 %>%
  filter(species.1 == "Largemouth Bass")%>%
  mutate(LMB = "Y")%>%
  select(1:5, 19) #13305 fish out of 13717

IN_GL_targeted_CIS <- in_glaciallakes_targeted_fish_1Sep2022 %>%
  filter(species.1 == "Cisco")%>%
  mutate(Cisco = "Y")%>%
  select(1:5, 19) #412

IN_GL_targeted_gear_check <- in_glaciallakes_targeted_fish_1Sep2022 %>%
  select(1:5)%>%
  group_by(lake_id, species.1)%>%
  summarise(Total_Catch = n())%>%
  pivot_wider(names_from = species.1, values_from = Total_Catch)

IN_GL_targeted_gear_check2 <- in_glaciallakes_targeted_effort_1Sep2022_2%>%
  select(1:8)%>%
  pivot_wider(names_from = sampling_method, values_from = year) #gill nets and EF not done in same survey. Different lakes sample with GN


IN_GL_targeted_GN <- in_glaciallakes_targeted_effort_1Sep2022_2 %>%
  filter(sampling_method == "experimental gill net")%>%
  select(1:8)

IN_GL_targeted_merge_check <- in_glaciallakes_targeted_fish_1Sep2022 %>%
  filter(species.1 == "Cisco")%>% 
  select(1:5)%>%
  left_join(IN_GL_targeted_GN, by = "lake_id")

```
email matt linn and ask about targeted survey gears (is EF just bass and GN just cisco)
- nope cisco are caught with electrofishing... see lake Eve... 
- ask about lake IDs too, email sent 11/10

merge IN GL targeted fish with effort
- 13,717 fish obs
- 51 survey/gear 
```{r}
# NOT WORKING BECAUSE SURVEY DATES DON'T MATCH


# set up key columns for merge
keycols_INGL_target <- c("lake_id", "date.1")

setkeyv(in_glaciallakes_targeted_effort_16Nov2023_2, keycols_INGL_target)
setkeyv(in_glaciallakes_targeted_fish_16Nov2023_2, keycols_INGL_target)

# merge IN glacial lakes targedted surveys effort and fish data
in_glaciallakes_target_merge <- merge(in_glaciallakes_targeted_fish_16Nov2023_2, in_glaciallakes_targeted_effort_16Nov2023_2, by = keycols_INGL_target, all = T, suffixes = c("_catch", "_effort")) #, roll = "nearest"

in_glaciallakes_target_merge_year <- in_glaciallakes_targeted_effort_16Nov2023_2 %>%
  group_by(lake_id, year,sampling_method)%>%
  summarise(number = n()) #have two targeted surveys with the same gear done twice in a year on a lake

in_glaciallakes_target_merge_2 <- in_glaciallakes_targeted_fish_16Nov2023_2 %>%
  full_join(in_glaciallakes_targeted_effort_16Nov2023_2, by = c("lake_id", closest(date.1)))
```

Check merge product for IN GL Targeted
```{r}
# NOT WORKING BECAUSE SURVEY DATES DON'T MATCH

# did we retain all surveys

in_glaciallakes_target_merge_survey <- in_glaciallakes_target_merge %>%
  group_by(lake_id, sampling_method, date.1)%>%
  summarise(Total = n()) 
    #yes all surveys were retained
    # fish were caught in every survey, makes sense because they are targeted

in_glaciallakes_target_merge_mismatch_f <- in_glaciallakes_target_merge %>%
   mutate(flag = case_when(lake_name.1_catch != lake_name.1_effort ~ "mismatched lake names",
                           county_catch != county_effort ~ "mismatched county names",
                          .default = NA))%>%
  mutate(lake_name_1 = if_else(lake_name.1_catch == lake_name.1_effort, lake_name.1_catch, lake_name.1_effort))%>%
  mutate(county = if_else(county_catch == county_effort, county_catch, county_effort))%>%
  filter(is.na(species.1))

in_glaciallakes_target_merge_mismatch_e <- in_glaciallakes_target_merge %>%
   mutate(flag = case_when(lake_name.1_catch != lake_name.1_effort ~ "mismatched lake names",
                           county_catch != county_effort ~ "mismatched county names",
                          .default = NA))%>%
  mutate(lake_name_1 = if_else(lake_name.1_catch == lake_name.1_effort, lake_name.1_catch, lake_name.1_effort))%>%
  mutate(county = if_else(county_catch == county_effort, county_catch, county_effort))%>%
  filter(is.na(sampling_method))%>%
  mutate(year = year(date.1))%>%
  distinct()

in_glaciallakes_target_fish_dates <- in_glaciallakes_targeted_fish_16Nov2023_2 %>%
  mutate(year = year(date.1))%>%
  select(lake_id, year, date.1)%>%
  rename(fish_catch_date = date.1)%>%
  distinct()

in_glaciallakes_target_effort_dates <- in_glaciallakes_targeted_effort_16Nov2023_2 %>%
  mutate(year = year(date.1))%>%
  select(lake_id, year, date.1)%>%
  rename(effort_date = date.1)%>%
  distinct()

in_glaciallakes_target_date_compare <- in_glaciallakes_target_fish_dates %>%
  full_join(in_glaciallakes_target_effort_dates, by = c("lake_id", "year"))%>%
  mutate(result = case_when(fish_catch_date == effort_date))

in_GL_targ_date_mismatch <- in_glaciallakes_target_merge_mismatch_e%>%
  full_join(in_glaciallakes_target_merge_mismatch_f, by = c("lake_id", "year"))%>%
  select(lake_id, year, date.1.x, date.1.y,county_catch.x, county_catch.y, county_effort.x, county_effort.y)%>%
  distinct()
#Date isn't matching up... see if we can match on year, and if year isn't sufficient, match on month and Year

# tidy column order and names
in_glaciallakes_target_merge_tidy <- in_glaciallakes_target_merge %>%
   mutate(flag = case_when(lake_name.1_catch != lake_name.1_effort ~ "mismatched lake names",
                           county_catch != county_effort ~ "mismatched county names",
                           lake_name.1_effort == "Golden" & year == "2017" ~ "fish date off by one day of effort date",
                          .default = NA))%>%
  mutate(lake_name_1 = if_else(lake_name.1_catch == lake_name.1_effort, lake_name.1_catch, lake_name.1_effort))%>%
  mutate(county = if_else(county_catch == county_effort, county_catch, county_effort))%>%
  rename(state = state_catch, #rename to match other parquet files
         date_1 = date.1,
         total_effort_1_units = effort_units.1,
         species_1 = species.1,
         length_1 = length.1,
         length_unit_1 = length_unit.1)%>%
  mutate(date_1 = as.IDate(date_1))%>%
  mutate(survey_type = if_else(!is.na(targeted_or_standard_catch), targeted_or_standard_catch, targeted_or_standard_effort))%>%
  select(state, 
         county, 
         lake_name_1, 
         lake_id,
         date_1,
         survey_type,
         sampling_method,
         total_effort_1,
         total_effort_1_units,
         species_1) #re-order columns, and remove irrelevant columns, can add more columns in this line too
```
    
    # still needs nhd IDs and lat longs if possible
    # add "total_effort_ident" after r bind with reservoirs


### temporary merge of IN Glacial Lakes targeted surveys

- survey dates aren't matching, will email Matthew about it, for now, just gathering ones that DO match so we can get a preliminary IN product

See line 395 for where data is prepped for merge
```{r}
in_glaciallakes_targeted_inner_join <- in_glaciallakes_targeted_fish_16Nov2023_2 %>%
  inner_join(in_glaciallakes_targeted_effort_16Nov2023_2, by = c("lake_id", "date.1"),
             suffix = c("_catch", "_effort"))
    # lose 10,051 fish obs and 31 surveys

in_glaciallakes_targeted_inner_join_tidy <- in_glaciallakes_targeted_inner_join %>%
  mutate(flag = case_when(lake_name.1_catch != lake_name.1_effort ~ "mismatched lake names",
                           county_catch != county_effort ~ "mismatched county names",
                           lake_name.1_catch != lake_name.1_effort ~ "mismatched lake names",
                          .default = NA))%>%
  mutate(lake_name_1 = if_else(lake_name.1_catch == lake_name.1_effort, lake_name.1_catch, lake_name.1_effort))%>%
  mutate(county = if_else(county_catch == county_effort, county_catch, county_effort))%>%
  rename(state = state_catch, #rename to match other parquet files
         date_1 = date.1,
         total_effort_1_units = effort_units.1,
         species_1 = species.1,
         length_1 = length.1,
         length_unit_1 = length_unit.1,
         year = year_catch,
         original_file_name_1_effort = original_file_name.1_effort,
         original_file_name_1_indivfish = original_file_name.1_catch)%>%
  mutate(date_1 = as.IDate(date_1))%>% #make date an IDate
  mutate(species_1 = str_to_lower(species_1))%>% #make species name lowercase
  mutate(species_1 = str_replace(species_1, " ", "_"))%>% #remove spaces from species name and put underscores
  mutate(survey_type = if_else(!is.na(targeted_or_standard_catch), targeted_or_standard_catch, targeted_or_standard_effort))%>%
  mutate(waterbody_type = "Glacial Lake")%>%
  select(state, 
         county, 
         lake_name_1, 
         lake_id,
         date_1,
         year,
         survey_type,
         sampling_method,
         total_effort_1,
         total_effort_1_units,
         species_1,
         length_1,
         length_unit_1,
         original_file_name_1_indivfish,
         original_file_name_1_effort,
         waterbody_type)

# do we want to add target species to targeted surveys..?
```


#Glacial Lakes 
```{r}
glimpse(in_glaciallakes_effort_16Nov2023)
glimpse(in_glaciallakes_fish_16Nov2023)

#
```



#Reservoir
```{r}
################aged fish#################
#age fish
glimpse(in_reservoir_age_fish_16Aug2022)

#age effort
glimpse(in_reservoir_age_effort_16Aug2022)

###############fish community#############
#fish
glimpse(in_reservoir_fish_community_fishdata_16Aug2022)

#effort
glimpse(in_reservoir_fish_community_effort_16Aug2022)

##############targeted surveys#######################
#fish
glimpse(in_reservoir_targeted_fish_1Sep2022)

#effort
glimpse(in_reservoir_targeted_effort_1Sep2022)

#community data set has the most fish so i will start there

#collapse fish into survey level - doesn't look like I need to uncount

#effort file has lake specific info that could be useful in linking (lat/long, lake_id)

#potienal steps could be linking effort via survey id and sampling method and retaining info from the survey file

#how do lake names align?
fish.lakes <- in_reservoir_fish_community_fishdata_16Aug2022 %>% 
  group_by(survey_id, lake_name.1) %>% 
  count() %>% 
  print(n = nrow(.))

effort.lakes <- in_reservoir_fish_community_effort_16Aug2022 %>% 
  group_by(survey_id,lake_name.1) %>% 
  count() %>% 
  print(n = nrow(.))

in_reservoir_fish_community_effort_16Aug2022 %>% 
  group_by(survey_id, date.1) %>% 
  count() %>% 
  print(n=nrow(.))
#survey ids only contain one date


#lake names seem to slightly differ between the two files, but survey ids are consist
#no dates within the fish file, but if the survey ids are consist between the two files that should be okay

in_reservoir_fish_community_fishdata_16Aug2022 %>% 
  group_by(survey_id, sampling_method) %>% 
  count() %>% 
  print( n= nrow(.))
#multiple survey types per survey id


#how can i get sampling method within the effort file?
in_reservoir_fish_community_effort_16Aug2022 %>% 
  group_by(total_effort_1, total_effort_2, total_effort_3) %>% 
  count()
#data explainer says:
#1. total_effort_1 reports effort for electofishing
#2. total_effort_2 reports effort for gill netting
#3. total_effort_3 reports effort for trap netting 

#will joining on survey id work alright?
in_reservoir_fish_community_fishdata_16Aug2022 %>% 
  filter(is.na(survey_id))
in_reservoir_fish_community_effort_16Aug2022 %>% 
  filter(is.na(survey_id))
#921 surveys without an id - this will be a problem
#raw data only shows 79 rows/surveys - not sure why it reads in more 

in_reservoir_fish_community_effort_16Aug2022 %>% 
  filter(is.na(survey_id)) %>% 
  glimpse()
```

Notes about reservoir data:
-Lake names between effort and fish files were not consistent 
-The Lake ID and date are only found int the effort file
-Given the two points above, I merged effort and fish files together using survey id and sampling method
-total effort is stored in a wide format - conversion to long format was needed
-ages that do not have a corresponding fish in the community or targeted surveys were left in the file and can be easily filtered out

Questions about the data themselves:
- For standard fish community surveys cypress lake seems to have a miss match survey id (273 and 373)
- In targeted surveys, 512 Dogwood has effort for standard trap nets but no fish are in the fish file
- Only half of the ages found partners of fish using survey id, length, weight, species, sampling method 
    -surveys that do not have any records besides age data: 373, 467, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490
    -survey that have matching community record but no corresponding fish: 379
    -surveys that have a matching survey id but mismatching survey info: 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480

#Reservoir effort merge
```{r}
#steps to get effort and fish together:
#1. generate sampling method for the effort file
#2. link the effort to the fish via survey id and sampling method
#3. retain or gather survey info from effort file or the lake id list


#generating sampling method for the effort file
in_reservoir_fish_community_effort_16Aug2022_gear <- in_reservoir_fish_community_effort_16Aug2022 %>%
  filter(!is.na(survey_id)) %>% 
  pivot_longer(cols = c(total_effort_1, total_effort_2, total_effort_3), names_to = "sampling_method", values_to = "total_effort" ) %>%  # make data longer, so that effort is in a single column
  mutate(sampling_method = case_when(sampling_method == "total_effort_1" ~ "Night EF",
                                     sampling_method == "total_effort_2" ~ "Gill net std exp",
                                     sampling_method == "total_effort_3" ~ "Trap net std"))%>% # write out sampling method
  mutate(effort_units = case_when(sampling_method == "Night EF" ~ "hours",
                                  sampling_method == "Gill net std exp" ~ "number of nets",
                                  sampling_method == "Trap net std" ~ "number of nets"))%>% # write out effort units
  relocate(survey_id, lake_name.1, lake_id, date.1, end_date, survey_type.1, sampling_method, total_effort, effort_units)%>% #bring these columns to the front 
  select(-effort_units.1, -effort_units.2, -effort_units.3)

anti.effort <- anti_join(in_reservoir_fish_community_effort_16Aug2022_gear, 
                          in_reservoir_fish_community_fishdata_16Aug2022, 
                          by = c("survey_id", "sampling_method"))

anti.fish <- anti_join(in_reservoir_fish_community_fishdata_16Aug2022,
                       in_reservoir_fish_community_effort_16Aug2022_gear,
                       by = c("survey_id", "sampling_method"))
#this shows a mismatch in survey ids at cypress lake between the effort and fish data
#there was a difference in the sampling method spelling for a few records at Summit
#fish data must be fixed to insure they join together 

#prepping fish data for merge
in_reservoir_fish_community_fishdata_16Aug2022_prep <- in_reservoir_fish_community_fishdata_16Aug2022 %>% 
  mutate(sampling_method = case_when(sampling_method == "Gill net STB exp" ~ "Gill net std exp",
                                     TRUE ~ sampling_method))  %>% #sampling method difference for a few records of fish
  mutate(survey_id = case_when((survey_id == 373 & lake_name.1 == "Cypress Lake") ~ 273,
                               TRUE ~ survey_id)) #difference in survey id at cypress lake

in.community <- inner_join(in_reservoir_fish_community_effort_16Aug2022_gear, 
                          in_reservoir_fish_community_fishdata_16Aug2022_prep, 
                          by = c("survey_id", "sampling_method")) %>% 
  select(state.x,
         survey_id,
         lake_name.1.x,
         lake_id,
         date.1,
         end_date,
         survey_type.1,
         sampling_method,
         total_effort,
         effort_units,
         lat_unspec,
         lon_unspec,
         species.1,
         length.1,
         weight.1,
         length_unit.1,
         weight_unit.1,
         gear_data_notes.1,
         original_file_name.1.x,
         original_file_name.1.y) %>% 
  rename(state = state.x,
         lake_name.1 = lake_name.1.x,
         original_file_name.1_effort_standard = original_file_name.1.x,
         original_file_name.1_fish_standard = original_file_name.1.y)

#targeted surveys
in_reservoir_targeted_effort_1Sep2022_gear <- in_reservoir_targeted_effort_1Sep2022 %>% 
  filter(!is.na(survey_id)) %>% 
  pivot_longer(cols = c(total_effort_1, total_effort_2, total_effort_3, total_effort_4, total_effort_5), names_to = "sampling_method", values_to = "total_effort" ) %>% 
  mutate(sampling_method = case_when(sampling_method == "total_effort_1" ~ "Night EF",
                                     sampling_method == "total_effort_2" ~ "Gill net std exp",
                                     sampling_method == "total_effort_3" ~ "Trap net std",
                                     sampling_method == "total_effort_4" ~ "MITN",
                                     sampling_method == "total_effort_5" ~ "Large-mesh GN"))%>% # write out sampling method
  mutate(effort_units = case_when(sampling_method == "Night EF" ~ "hours",
                                  sampling_method == "Gill net std exp" ~ "number of nets",
                                  sampling_method == "Trap net std" ~ "number of nets",
                                  sampling_method == "MITN" ~ "number of nets",
                                  sampling_method == "Large-mesh GN" ~ "number of nets")) %>% 
  relocate(survey_id, lake_name.1, lake_id, date.1, end_date, survey_type.1, sampling_method, total_effort, effort_units)%>% #bring these columns to the front 
  select(-effort_units.1, -effort_units.2, -effort_units.3, -effort_units.4, -effort_units.5) %>% 
  filter(!is.na(total_effort))

anti.effort <- anti_join(in_reservoir_targeted_effort_1Sep2022_gear, 
                         in_reservoir_targeted_fish_1Sep2022, 
                          by = c("survey_id", "sampling_method"))

anti.fish <- anti_join(in_reservoir_targeted_fish_1Sep2022,
                       in_reservoir_targeted_effort_1Sep2022_gear,
                       by = c("survey_id", "sampling_method"))

anti.fish %>% 
  group_by(survey_id, lake_name.1, sampling_method) %>% 
  count()

in_reservoir_targeted_fish_1Sep2022 %>% 
  filter(is.na(survey_id)) %>% 
  group_by(lake_name.1, species.1, length.1) %>% 
  count()
#no fish records in 512 for the standard trap effort - all fish are are a MITN... is it really nothing caught with 35 nets?
#200 records that have everything as just na - similar to what I have been seeing in the effort data

#prepping fish data for merge
in_reservoir_targeted_fish_1Sep2022_prep <- in_reservoir_targeted_fish_1Sep2022 %>% 
  filter(!is.na(survey_id))

in.targeted <- inner_join(in_reservoir_targeted_effort_1Sep2022_gear, 
                          in_reservoir_targeted_fish_1Sep2022_prep, 
                          by = c("survey_id", "sampling_method")) %>% 
  select(state.x,
         survey_id,
         lake_name.1.x,
         lake_id,
         date.1,
         end_date,
         survey_type.1,
         sampling_method,
         total_effort,
         effort_units,
         lat_unspec,
         lon_unspec,
         species.1,
         length.1,
         weight.1,
         length_unit.1,
         weight_unit.1,
         gear_data_notes.1,
         original_file_name.1.x,
         original_file_name.1.y) %>% 
    rename(state = state.x,
          lake_name.1 = lake_name.1.x,
          original_file_name.1_effort_targeted = original_file_name.1.x,
          original_file_name.1_fish_targeted = original_file_name.1.y)

#combining targeted and community surveys
in_reservoir_data_noage <- bind_rows(in.community, in.targeted)


#aged fish
in_reservoir_age_fish_16Aug2022 %>% 
  group_by(sampling_method) %>% 
  count()

in_reservoir_age_fish_16Aug2022 %>% 
  group_by(species.1) %>% 
  count()

in_reservoir_data_noage %>% 
  group_by(species.1) %>% 
  count() %>% 
  print(n = nrow(.))

in_reservoir_age_fish_16Aug2022_merge  <-  in_reservoir_age_fish_16Aug2022 %>%
  filter(!is.na(survey_id)) %>% 
  arrange(survey_id, species.1, sampling_method, length.1, weight.1) %>% 
  group_by(survey_id,species.1, sampling_method, length.1, weight.1) %>% 
  mutate(age_id = row_number()) %>% 
  ungroup() %>% 
  mutate(length.1 = as.double(length.1),
         weight.1 = as.double(weight.1)) %>% 
  mutate(sampling_method = case_when(sampling_method %in% c("IN Standard Net", "Gill net") ~ "Gill net std exp",
                                     TRUE ~ sampling_method)) %>% 
  select(survey_id, 
         sampling_method, 
         species.1,
         length.1, 
         weight.1,
         age_id, 
         age, 
         aging_structure.1, 
         original_file_name.1) %>% 
  rename(original_file_name.1_age = original_file_name.1)

in_reservoir_data_age <- in_reservoir_data_noage %>% 
  arrange(survey_id, species.1, sampling_method, length.1, weight.1) %>% 
  group_by(survey_id, species.1, sampling_method, length.1, weight.1) %>% 
  mutate(age_id = row_number())

#matching with community fish
in_reservoir_data <- full_join(in_reservoir_data_age,
                                  in_reservoir_age_fish_16Aug2022_merge,
                                    by = c("survey_id",
                                           "sampling_method",
                                           "species.1",
                                           "length.1",
                                           "weight.1",
                                           "age_id")) 
glimpse(in_reservoir_data)

#aged fish that do not have a match
anti.age <- anti_join(in_reservoir_age_fish_16Aug2022_merge,
                      in_reservoir_data,
                                    by = c("survey_id",
                                           "species.1",
                                           "sampling_method",
                                           "length.1",
                                           "weight.1",
                                           "age_id"))
#surveys of aged fish that do not have a match
anti.age %>% 
  group_by(survey_id, sampling_method) %>% 
  count() %>% 
  print(n = nrow(.))
#I was only able to match about half of the fish 
#surveys that do not have any records besides age data: 373, 467, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490
#survey that have matching community record but no corresponding fish: 379
#surveys that have a matching survey id but mismatching survey info: 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480

#currently all age data is put in - ages that did not match to surveyed fish can easily be filtered out but na lake name/survey id/ect. - you can also see that they have an original file for age but not for effort/fish 

#I will wait to clean up data with glacial lakes 
#Items that will need to be cleaned up: length/weight units, species, creation of a total effort ident
```


Mike Example code
```{r}
# view each data level for a single survey
mi_statustrends_effort_16Mar2021[survey_id ==2446]
mi_statustrends_catch_16Mar2021[survey_id == 2446]
mi_statustrends_catchlengthclass_03July2023[survey_id == 2446, ]
mi_statustrends_lenage_20May2021[survey_id == 2446, ]

# do the counts match across all levels?
mi_statustrends_catch_16Mar2021[survey_id == 2446, sum(total_count)]
mi_statustrends_catchlengthclass_03July2023[survey_id == 2446, sum(total_count)]
nrow(mi_statustrends_lenage_20May2021[survey_id == 2446, ])

#no. not even close. I suspect this is bc of a species seletion that happened in the catch data:
mi_statustrends_catch_16Mar2021[survey_id == 2446, length(unique(species.1))]
mi_statustrends_catchlengthclass_03July2023[survey_id == 2446, length(unique(species.1))]
mi_statustrends_lenage_20May2021[survey_id == 2446, length(unique(species.1)) ]
#view species lists:
mi_statustrends_catch_16Mar2021[survey_id == 2446,sum(total_count) , species.1]
mi_statustrends_catchlengthclass_03July2023[survey_id == 2446,sum(total_count) , species.1]
mi_statustrends_lenage_20May2021[survey_id == 2446, .N , species.1 ] # these numbers will not be the same. This is because these aged fish are a subset.
#view species lists:
mi_statustrends_catch_16Mar2021[survey_id == 4079,sum(total_count) , species.1]
mi_statustrends_catchlengthclass_03July2023[survey_id == 4079,sum(total_count) , species.1]
mi_statustrends_lenage_20May2021[survey_id == 4079, .N , species.1 ] # these numbers will not be the same. This is because these aged fish are a subset.



# not exactly clear WHY the numbers still don't jive between the inch grp file and the catch file, BUT the catch file seems to have problems with the n per species X gear where there are zeros in an inchgroup (see survey 2446)


#survey_ids matched across all surveys?
mi_statustrends_effort_16Mar2021[ , .( effort_nrows = .N) , survey_id]
mi_statustrends_catch_16Mar2021[ , .( catch_nrows = .N) , survey_id]
mi_statustrends_catchlengthclass_03July2023[ , .( catchlen_nrows = .N) , survey_id ]
mi_statustrends_lenage_20May2021[ , .( lenage_nrows = .N) , survey_id] 

#data summary by surveys
data_coverage <- 
merge(
  merge(
  merge(
    merge(mi_statustrends_effort_16Mar2021[ , .( effort_nrows = .N) , survey_id], 
          mi_statustrends_catch_16Mar2021[ , .( catch_nrows = .N) , survey_id], all = T),
    mi_statustrends_catchlengthclass_03July2023[ , .( catchlen_nrows = .N) , survey_id ], all = T), 
  mi_statustrends_lenage_20May2021[ , .( lenage_nrows = .N) , survey_id], all = T),
  mi_survey_id_crosswalk_23May2023[,.(crosswalk_nrows = .N) , Survey_Number ],by.x = "survey_id", by.y = "Survey_Number", all = T)
  



```


# Effort Merge
```{r}
#in this chunk you join the effort data to the fish-as-rows or obs-level dataset. I start by prepping these multiple files for a merge. After each operation, be sure to check your work! Again I have left MI in here to give you an idea of how one previous example went. 



#Start with a merge of catch and catch-length?

        #file prep
                #dates
                        # mi_statustrends_effort_16Mar2021[ , unique(date.1) , ]
                        mi_statustrends_effort_16Mar2021[ , date.1 := as.character(date.1) , ]
                        # mi_statustrends_catch_16Mar2021[ , unique(date.1) , ]
                        mi_statustrends_catch_16Mar2021[ , date.1 := as.character(as.IDate(date.1, format = "%m/%d/%Y")) , ]
                #species        
                        #species is empty in effort
                        mi_statustrends_effort_16Mar2021[ , .N , species.1 ]
                        mi_statustrends_effort_16Mar2021[ , species.1 := NULL ,]
                        
                        #view species lists:
                        mi_statustrends_catch_16Mar2021[ ,sum(total_count) , species.1]
                        mi_statustrends_catchlengthclass_03July2023[ ,sum(total_count) , species.1]
                        mi_statustrends_lenage_20May2021[ , .N , species.1 ] # these numbers will not be the same. This is because these aged fish are a subset.
                        
                        #dump the species not of interest to us here:
                        mi_statustrends_catchlengthclass_03July2023 <- mi_statustrends_catchlengthclass_03July2023[species.1 %in% mi_statustrends_catch_16Mar2021[ , unique(species.1)]]
                        
                        #column name diffs
                        colnames(mi_statustrends_catchlengthclass_03July2023)[colnames(mi_statustrends_catchlengthclass_03July2023)== "sampling_method" ] <- "sampling_method_abbrev"
                        
                        #add lake_id to lengthclass file:
                        mi_statustrends_catchlengthclass_03July2023[mi_statustrends_effort_16Mar2021[ ,.N , .(lake_id, lake_name.1, survey_id)], on = c("lake_name.1", "survey_id"), lake_id := lake_id ] 
                        mi_statustrends_catchlengthclass_03July2023[is.na(lake_id), .N , .(lake_name.1, survey_id)]#still missing names
                        
                        #any more available in catch file? NOPE
                        mi_statustrends_catchlengthclass_03July2023[is.na(lake_id), .N , .(lake_name.1, survey_id)][,survey_id]%in%
                        mi_statustrends_catch_16Mar2021[ ,.N , .(lake_id, lake_name.1, survey_id)][ , survey_id]
                        
                        #if drawn from effort sans survey ID (Risky, ambiguous join) can we get a 1:1 for lake name? or is there multi lakes for each name?
                        mi_statustrends_effort_16Mar2021[ lake_name.1 %in%
                                                            mi_statustrends_catchlengthclass_03July2023[is.na(lake_id), .N , .(lake_name.1, survey_id)][,lake_name.1] , .N ,
                                                          .(lake_id, county, lake_name.1, year, survey_id, survey_type.1) ]
                        #if drawn from catch sans survey ID (Risky, ambiguous join) can we get a 1:1 for lake name? or is there multi lakes for each name?
                        mi_statustrends_catch_16Mar2021[ lake_name.1 %in%
                                                           mi_statustrends_catchlengthclass_03July2023[is.na(lake_id), .N , .(lake_name.1, survey_id)][,lake_name.1] , .N ,
                                                         .(lake_id, county, lake_name.1, year, survey_id, survey_type.1) ]
                        
                        #Conclusion-- don't do that. only grab the full keyed lake IDs from effort:
                        mi_statustrends_catchlengthclass_03July2023[mi_statustrends_catch_16Mar2021[ ,.N , .(lake_id, lake_name.1, survey_id)], on = c("lake_name.1", "survey_id"), lake_id := lake_id ]
        #uncount catch
                        #uncount the catch files into an indiv-as-row format:
                        #with lengths scope
                        mi_statustrends_catchlengthclass_03July2023[ ,summary(total_count) , ]
                        mi_statustrends_catchlengthclass_03July2023[ , .N , total_count == 0] #do we lose anything if we drop these?
                        
                        #here we check if the surveyXsample methods are all covere in the >0 total_count data (same dataset)
                        mi_statustrends_catchlengthclass_03July2023[total_count == 0 , .N , .(survey_id, sampling_method_abbrev)]
                        sum(!mi_statustrends_catchlengthclass_03July2023[total_count == 0 , paste(survey_id, sampling_method_abbrev)] %in% mi_statustrends_catchlengthclass_03July2023[total_count>0, paste(survey_id,sampling_method_abbrev)])
                        #how about in the effort data? There's no effort data that we would lose if we drop those zeros. 
                        sum(!mi_statustrends_catchlengthclass_03July2023[total_count == 0 , paste(survey_id, sampling_method_abbrev)] %in% mi_statustrends_effort_16Mar2021[, paste(survey_id,sampling_method_abbrev)])
                        
                        #execute the uncount, dropping those zero total counts in the mix (This line is generating a warning in the next line)
                        mi_statustrends_catchlengthclass_03July2023_uncount <- 
                                       uncount(mi_statustrends_catchlengthclass_03July2023[total_count!=0], total_count, .remove = T, .id = "ident_l")
                        
                        #add a surveyxgear ident for indiv fish
                        mi_statustrends_catchlengthclass_03July2023_uncount[ , ident := seq_len(.N) , .(lake_name.1, lake_id, survey_id, sampling_method_abbrev, species.1) ]
                        
                        #no lengths scope          
                        mi_statustrends_catch_16Mar2021[ , summary(total_count)]
                        #execute
                        mi_statustrends_catch_16Mar2021_uncount <- 
                          uncount(mi_statustrends_catch_16Mar2021, total_count, .remove = T, .id = "ident")

        
                        
          #how many length data cover unknown surveys in catch data?
                        
                        #here we check if the surveyXsample methods are all covered in the simple catch data
                        mi_statustrends_catchlengthclass_03July2023_uncount[ , .N , .(survey_id, sampling_method_abbrev)]
                        sum(!mi_statustrends_catchlengthclass_03July2023_uncount[ , unique(paste(survey_id, sampling_method_abbrev))] %in% mi_statustrends_catch_16Mar2021_uncount[, unique(paste(survey_id,sampling_method_abbrev))])
                        
                        #how about in the effort data? There's no effort data that we would lose if we drop those zeros, but we do have 3 surveyXgears unique to the inchclass data. 
                        sum(!mi_statustrends_catchlengthclass_03July2023_uncount[ , unique(paste(survey_id, sampling_method_abbrev))] %in% mi_statustrends_effort_16Mar2021[, paste(survey_id,sampling_method_abbrev)])
                        
                        # we can see that 3 surveys in inchclass data are not represented in catch or effort data
                        mi_statustrends_catchlengthclass_03July2023_uncount[ , unique(paste(survey_id, sampling_method_abbrev))][!mi_statustrends_catchlengthclass_03July2023_uncount[ , unique(paste(survey_id, sampling_method_abbrev))] %in% mi_statustrends_effort_16Mar2021[, paste(survey_id,sampling_method_abbrev)]]
                        
                        mi_statustrends_effort_16Mar2021[survey_id == 4042]
                        
                        mi_statustrends_catchlengthclass_03July2023_uncount[ survey_id == 4042, .N , .(species.1, sampling_method_abbrev) ]
                        
        #are there any surveys without any catch? Yes, 120 of them. (can we assume catch = zero there? Likely yes )
                        sum(!
                              mi_statustrends_effort_16Mar2021[ , 
                                                                unique(paste(survey_id, sampling_method_abbrev))
                                                                ] %in%
                              mi_statustrends_catch_16Mar2021_uncount[ ,
                                                                       unique(paste(survey_id, sampling_method_abbrev)) ,
                                                                       ]
                            )
                        
                        mi_statustrends_catch_16Mar2021[ , summary(total_count) ,]
        
        # and how many surveyX gears are not shown in the effort file? ZERO!                
                        sum(!mi_statustrends_catch_16Mar2021_uncount[ ,
                                                                       unique(paste(survey_id, sampling_method_abbrev)) ,
                                                                       ] %in%
                              mi_statustrends_effort_16Mar2021[ , 
                                                                unique(paste(survey_id, sampling_method_abbrev))
                                                                ]
                              
                            )
                       #this tells us we can skip expansion here. These no catch are already captured in the effort file
                        
         #merge catch files:                
                        names(mi_statustrends_catch_16Mar2021_uncount)
                        colnames(mi_statustrends_catchlengthclass_03July2023_uncount)
                        
                        
                        #set key columns
                        keycols <- c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev", "species.1", "ident")
                        setkeyv(mi_statustrends_catch_16Mar2021_uncount, keycols )
                        setkeyv(mi_statustrends_catchlengthclass_03July2023_uncount, keycols )
                        
                        #merge together all catch data
                        mi_catch_merge <- merge(mi_statustrends_catch_16Mar2021_uncount, mi_statustrends_catchlengthclass_03July2023_uncount, by = keycols, all = T, suffixes = c("_catch", "_catchlengths"))
                        

          #add ages where we've got em' (ambiguous gears means we can't tie these to catch-- they're going to go into the mi flat file without gear assigned)
                        # #add an ident
                        # mi_statustrends_lenage_20May2021[ , ident := seq_len(.N) , .(lake_id, survey_id, sampling_method_abbrev, species.1) ]
                        # #set key columns
                        # keycols <- c("lake_id", "survey_id", "sampling_method_abbrev", "species.1", "ident")
                        # setkeyv(mi_statustrends_catch_16Mar2021_uncount, keycols )
                        # setkeyv(mi_statustrends_catchlengthclass_03July2023_uncount, keycols )
                        # 
                        # #merge together all catch data
                        # mi_catch_merge <- merge(mi_statustrends_catch_16Mar2021_uncount, mi_statustrends_catchlengthclass_03July2023_uncount, by = keycols, all = T, suffixes = c("_catch", "_catchlengths"))
                        
                                       
          #merge effort into this
                        
                        #set key columns
                        keycols <- c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev")
                        setkeyv(mi_catch_merge, keycols )
                        setkeyv(mi_statustrends_effort_16Mar2021, keycols )
                        
                        #drop survey level info that will otherwise get duplicated upon  merge() (DONT DO THIS HERE, WILL LOSE DATA-- SEE data_coverage table)
                        data_coverage[ ,.N , .("effortNA" = is.na(effort_nrows), "catchlenNA" = is.na(catchlen_nrows))]
                        data_coverage[ ,.N , .("effortNA" = is.na(effort_nrows), "catchNA" = is.na(catch_nrows))]
                        
                        
                        #do merge
                        mi_catch_eff_merge <- merge(mi_catch_merge, mi_statustrends_effort_16Mar2021, by = keycols, all = T, suffixes = c("_mergedcatch", "_effort"))
                        
``` 
          
          
# Data tidying                        
```{r}                       
### dataset cleanup and tidying. MI work left here as an idea of a previous state's work



                                               
                        #check the product:
                        colnames(mi_catch_eff_merge)
                        
                       mi_catch_eff_merge[ str_detect(lake_name.1, "ike" ), .(count = .N, missinglengths = sum(is.na(length.1)), meanL = mean(length.1)), .(lake_name.1, lake_id, date.1_effort, date.1_mergedcatch, survey_id, sampling_method_abbrev, species.1) ]

            
                        #did we retain all of the surveys? Looks like 498 unique survey IDs, and both the product and input reflect this:
                        mi_catch_eff_merge[ , .N , .(survey_id)]
                        merge(merge(mi_statustrends_effort_16Mar2021[ , .( effort_nrows = .N) , survey_id], 
                                    mi_statustrends_catch_16Mar2021[ , .( catch_nrows = .N) , survey_id], all = T),
                              mi_statustrends_catchlengthclass_03July2023[ , .( catchlen_nrows = .N) , survey_id ], all = T)
                       
                       
                        #here's all of our effort:
                        mi_catch_eff_merge[ , .N ,   c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev") ]
                        #no catch data exist (or matched) for these data:
                        mi_catch_eff_merge[ is.na(species.1)  , .N ,   c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev") ]
                        #no_taxa_found
                        mi_catch_eff_merge[   , nothing_caught  := is.na(species.1) ,  ]
                        
                        
                        #no effort data were submitted for these fish:
                        mi_catch_eff_merge[ is.na(date.1_effort)  , .N ,   c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev") ]

                        
       #clean up the column names and tidy the data table up a bit                 
       
              sort(colnames(mi_catch_eff_merge))                 
              
              #county     
              mi_catch_eff_merge[ is.na(county_mergedcatch)|is.na(county_effort) , .N ,   ]
              mi_catch_eff_merge[ !(is.na(county_mergedcatch)&is.na(county_effort)) & county_mergedcatch != county_effort  , .N ,   ]# no cases where the county doesn't match
              mi_catch_eff_merge[  , .N , .(is.na(county_mergedcatch), is.na(county_effort))  ]#there are some cases where we haven't got a county at all, otherwise the effort county covers all. 
              mi_catch_eff_merge[  , county_mergedcatch := NULL]
              setnames(mi_catch_eff_merge, "county_effort", "county")
              
              #data_type
              setnames(mi_catch_eff_merge, "data_type", "data_type_effort")
                   
              #date.1
              mi_catch_eff_merge[ is.na(date.1_mergedcatch)|is.na(date.1_effort) , .N ,   ]
              mi_catch_eff_merge[ !(is.na(date.1_mergedcatch)&is.na(date.1_effort)) & date.1_mergedcatch != date.1_effort  , .N ,   ]# no cases where the dates don't match
              mi_catch_eff_merge[  , .N , .(is.na(date.1_mergedcatch), is.na(date.1_effort))  ]#there are some cases where we haven't got a date at all, otherwise the effort info covers all. 
              mi_catch_eff_merge[  , date.1_mergedcatch := NULL]
              setnames(mi_catch_eff_merge, "date.1_effort", "date.1")
              
              #date recieved
              setnames(mi_catch_eff_merge, "date_recieved", "date_recieved_effort")
              
              #effort units
              mi_catch_eff_merge[ is.na(effort_units.1_mergedcatch)|is.na(effort_units.1_effort) , .N ,   ]
              mi_catch_eff_merge[ !(is.na(effort_units.1_mergedcatch)&is.na(effort_units.1_effort)) & effort_units.1_mergedcatch != effort_units.1_effort  , .N ,   ]# no cases where the units don't match
              mi_catch_eff_merge[  , .N , .(is.na(effort_units.1_mergedcatch), is.na(effort_units.1_effort))  ]#we have efforts for all. slide into single column. 
              
              mi_catch_eff_merge[is.na(effort_units.1_effort), .N , ]
              mi_catch_eff_merge[is.na(effort_units.1_effort) , effort_units.1_effort := effort_units.1_mergedcatch , ]
              mi_catch_eff_merge[ , effort_units.1_mergedcatch := NULL , ]
               setnames(mi_catch_eff_merge, "effort_units.1_effort", "effort_units.1")
              
              #filenumber
              setnames(mi_catch_eff_merge, "file_number", "file_number_effort")
              
              #state
              mi_catch_eff_merge[ ,state := "Michigan"  ] 
              mi_catch_eff_merge[ , `:=` (state_catch = NULL, state_catchlengths = NULL)  , ]
              
              #total effort
              mi_catch_eff_merge[total_effort_1.1_effort != total_effort_1.1_mergedcatch, .N,  ]
              plot(total_effort_1.1_effort ~ total_effort_1.1_mergedcatch, data = mi_catch_eff_merge  )
              abline(1,0)
              
              #effort vals
              mi_catch_eff_merge[ total_effort_1.1_effort != total_effort_1.1_mergedcatch , .N , .(total_effort_1.1_mergedcatch, total_effort_1.1_effort)]
              #I think that the merged catch values were assigned to indiv fish (like "this fish was caught in ONE net lift") and the effort file has survey X gear total efforts
              mi_statustrends_catchlengthclass_03July2023[ , summary(total_effort_1.1) , ] 
                mi_statustrends_catchlengthclass_03July2023[total_effort_1.1 > 1 , summary(total_count), sampling_method_abbrev]
              # mi_statustrends_catch_16Mar2021[ , summary(total_effort_1.1) , ]    #this won run b/c no col for effort in that       
              mi_statustrends_effort_16Mar2021[ , summary(total_effort_1.1) ,]          
              # well--- I don't know what to make of all this, but for now I'll be keeping both of these "total_effort" variables, and leaning on the one originating in the effort file
              
              
              
              #year
              
              mi_catch_eff_merge[ year_effort != year_mergedcatch , ,]
              mi_catch_eff_merge[ , .N , .(is.na(year_effort), is.na(year_mergedcatch))]
              mi_catch_eff_merge[is.na(year_effort), year_effort := year_mergedcatch , ]
              mi_catch_eff_merge[ ,  year_mergedcatch := NULL , ]
              setnames(mi_catch_eff_merge, "year_effort", "year")
              
              
              # most of this is waste-of-time junk. Let's move the big ones left and leave this mess hang out there to the right.
              notgarbage <-  c("county","lake_id", "lake_name.1", "date.1", "year", "survey_id",  #survey 
                               "sampling_method_abbrev", "total_effort_1.1_effort", "effort_units.1", "nothing_caught",  #gear
                               "species.1", "ident", "length.1", "length_unit.1", "ident_l" #fish
                               )
              
              setcolorder(mi_catch_eff_merge, notgarbage)
               
              
        #expand these data to cover all interested species in each surveyXgear
                        
                        #check behavior now:
                        mi_catch_eff_merge[ species.1 == "WAE" , .N  , c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev") ]
                        #we can see that to gen a catch or CPUE dataset we can cast wide (like we did in MN)
        
        #generate a species obs matrix
                        #clean dates:
                        mi_catch_eff_merge[ , unique(date.1) , ]
                        
                        #execute
                        mi_catch_eff_merge[ , date_clean := as.IDate(date.1) ,]
                        mi_catch_eff_merge[ , summary(date_clean) , ]
                        mi_catch_eff_merge[ is.na(date_clean) , .N , .(survey_id, lake_name.1)] #missing effort data here, thus the gap
                        
                        
                        #tag codes with "taxon"
                        mi_catch_eff_merge[ , species.1 := paste("taxon_",species.1, sep = "")  ,]
                        
                        #we called this "wide complete" in MN
                        wide_complete <- dcast(mi_catch_eff_merge[ ,.N , by = c("county","lake_id", "lake_name.1", "date.1", "year", "survey_id",  #survey 
                                                                           "sampling_method_abbrev", "total_effort_1.1_effort", "effort_units.1", "nothing_caught", 
                                                                           "species.1"
                                                                           )] , ... ~ species.1 , value.var = "N", fill = 0)
                        
                        wide_complete[ , c("county","lake_id", "lake_name.1", "date.1", "year", "survey_id",  #survey 
                                                                           "sampling_method_abbrev", "total_effort_1.1_effort", "effort_units.1", "taxon_WAE") , ]
                        
                        wide_complete[taxon_NA >0]
                        
                        
          # saveRDS(mi_catch_eff_merge, file = "Data_and_Scripts/Data/output/mi_flat_effort_indivfish_merge.rds")                
                        
                        
                        
                        
```                        
                        
 


# Review & QC datasets
```{r}
#here I do some very basic checks on what the data structure and general outputs look like (i.e., s this thing behaving like the obs-level file I think it is?). MI work left here as an idea of a previous state's work. In my opinion, it is not our job to QC the actual observations at this point (like, is a WAE really going to be 500mm at age zero), but instead to use this QC as a check on the operations performed in this script.  



                        #effort per surveyXgear?
                        mi_catch_eff_merge[ , .(effort = first(total_effort_1.1_effort), units = first(effort_units.1)) ,   c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev")]
                        
                        #effort per survey type?
                        mi_catch_eff_merge[!is.na(total_effort_1.1_effort) , .(effort = first(total_effort_1.1_effort), units = first(effort_units.1), number = .N) ,   c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev")][ ,.(effort = sum(effort), counts = sum(number), grandCPUE = sum(number)/sum(effort)) , .(sampling_method_abbrev, units)]
                        
                        #effort per survey type (Walleye ONLY)?
                        mi_catch_eff_merge[!is.na(total_effort_1.1_effort) & species.1=="walleye" , .(effort = first(total_effort_1.1_effort), units = first(effort_units.1), number = .N) ,   c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev")][ ,.(effort = sum(effort), counts = sum(number), grandCPUE = sum(number)/sum(effort)) , .(sampling_method_abbrev, units)]
                        
                        
                        
                        #how many Walleye in surveys where we had effort data?
                        mi_catch_eff_merge[ species.1== "walleye"  , .("n_fish" = .N) , .(sampling_method_abbrev) ][, sum(n_fish)]
                        mi_catch_eff_merge[ , .N , species.1]
                        
                        
                        #whats the effort look like?
                        mi_catch_eff_merge[ ,.N, total_effort_1.1_effort ]
                        
                        # data coverage
                        # how many surveys were we missing effort data for? One survey, 3 gears. Survey 4042 on Twin Lake
                        mi_catch_eff_merge[ is.na(total_effort_1.1_effort), .N , ]
                        mi_catch_eff_merge[ is.na(total_effort_1.1_effort), c("numberofspp" = length(unique(species.1))) , c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev") ]
                        
                        
                        # how many surveys were we missing catch data from?
                        # how many surveys missing catchlength for?
                        mi_catch_eff_merge[ , .N, is.na(original_file_name.1_catch)]
                        mi_catch_eff_merge[ , .N, .(catchNA = is.na(original_file_name.1_catch),
                                                    catchlengthNA = is.na(original_file_name.1_catchlengths),
                                                    effortNA = is.na(original_file_name.1_effort))]
                        mi_catch_eff_merge[is.na(original_file_name.1_catch)]
                        
                        
                        
                        glimpse(mi_catch_eff_merge)
                        
                        
                        #Naming scheme updated to match overall approach:
                        
                      
                        

```


# Import/Export files

```{r}


#save to disk:

# saveRDS(mi_catch_eff_merge, file = "Data_and_Scripts\\Data\\output\\mi_flat_effort_indivfish_merge.rds")
# mi_catch_eff_merge <- readRDS(file = "Data_and_Scripts\\Data\\output\\mi_flat_effort_indivfish_merge.rds")


str(mi_catch_eff_merge)


mi_catch_eff_merge <- as_arrow_table(mi_catch_eff_merge)

write_dataset(dataset = mi_catch_eff_merge, path = "Data_and_Scripts/Data/output/mi_file_arrow")

mi_data <- open_dataset("Data_and_Scripts/Data/output/mi_file_arrow")

glimpse(mi_data)

```





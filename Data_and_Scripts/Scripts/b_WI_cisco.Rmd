---
title: "b_WI_cisco"
author: "Holly Masui"
date: "`r Sys.Date()`"
output: html_document
---

libraries
```{r}
library(arrow)
library(readr)
library(dplyr)
library(stringr)
library(data.table)
library(janitor)
library(tidyr)
library(lubridate)
library(ggplot2)
library(mwlaxeref)

options(scipen = 999)
```

Read in WI targeted Cisco Data
- in the future, get it to work with data explainer
```{r}
#generate a file list to import
files_list <- list.files(path = "D:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/Cisco targeted data/WI_Cisco", pattern = ".+\\.csv") #grabs only.csv files
files_list 



#object for use in loop (simple length of file list)
n <- length(files_list)

for(i in 1:n) {
  #i = 1
  filei <- word(gsub(".csv","", files_list[i]), start = -1, sep = fixed("/"))
  #this does those two steps in one package
  assign(filei ,
          fread(paste0("D:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/Cisco targeted data/WI_Cisco",
                                          files_list[i])))
  
  # if the file is a crosswalk, do not rename anything, just loop to the confirm import line
  if(str_detect(filei, "crosswalk")) {  #confirm import of files:  
    print(paste(filei ,"added to workspace" ))  
    #confirm import of files:  
    print(paste(i ,"files added to workspace" )) ; next}
  
  #if the file is not in the data explainer, don't try to rename it:
  if(filei %in% cde$new_file_name) {
    print("renaming with data explainer")
  } else {next}
  
  
  
  
  
  # note we want to review a sorted list of column names to check misspelling etc.
  # we still need to use the columns with names like col_name_length_in, or known_units
  
  
  cde %>% # call data explainer file
    filter(`new_file_name`== filei)%>% #keep only the row relevant to this file
    select_if(~ !any(is.na(.))) %>% 
    data.table::transpose(keep.names = "newname") %>% 
    rename("oldname" = V1) %>% 
    assign("names", ., envir = .GlobalEnv)
  
  #see if any column names will not have a match! 
  # IF any pop FALSE, force stop and revisit of data explainer ()
  # - e.g., named something "total catch" when actual column name was "total_catch"
  print(
    cbind(colnames(get(filei)),
          colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
    )
  )
  
  
  # break the loop if the current file has column names not in the data explainer
  # if (all(cbind(colnames(get(filei)),  colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ])[,2]) == FALSE ) break
  if (all(colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]) == FALSE ) break
  
  
  # append old col names into new "notes" columns:
  get(filei)[ , (names[ str_detect(newname, "notes") , oldname   ,  ]) := Map(paste, colnames(.SD), .SD, sep = ':') , .SDcols =  names[ str_detect(newname, "notes") , oldname   ,  ] ]
  
  #now rename that file's colnames
  setnames(get(filei), colnames(get(filei)), names[!str_detect(newname,"unique_row_key")] [match(names(get(filei)),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )
  
  #append all other data from data explainer
  unusedbits <- 
    data.table(
      matrix(
        rep(names[ !newname %in% colnames(get(filei)) , oldname , ],
            each = nrow(get(filei))
        ),
        nrow = nrow(get(filei)),
        dimnames = list(rep(NA,nrow(get(filei))),
                        names[ !newname %in% colnames(get(filei)) , newname , ])
        )
      )
  
  #add all not yet used columns from data explainer:
  get(filei)[ , (names[ !newname %in% colnames(get(filei)) , newname , ]) := unusedbits[] ]

  #confirm import of files:  
  print(paste(filei ,"added to workspace" ))  
  #confirm import of files:  
  print(paste(i ,"files added to workspace" )) 

  
} 
  #confirm import of files:  
  print(paste(i ,"files added to workspace" ))
  #confirm import of files:  
  print(paste(n-i ,"remaining to be added" )) 



```

Read in Cisco data
```{r}
wi_target_cisco8nov2023 <- read_csv("D:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/Cisco targeted data/WI_Cisco/wi_target_cisco8nov2023.csv")
```

clean WI targeted cisco data so that it can match the format of the regular wi data

This code chunk renames columns, and selects for the columns of interest
```{r}
wi_cisco_clean <- wi_target_cisco8nov2023 %>%
  mutate(original_file_name = "WisconsinUpdated_Inland_stratified_lakes_coldwater_fishes_cisco-whitefish_only_Lyons.xlsx")%>%
  rename(lake_name = Lake,
         date = VGN_Date,
         lake_id = WBIC,
         waterbody_type = Type,
         lat_unspec = Lat,
         lon_unspec = Lon,
         total_count = VGN_Cisco,
         total_effort_1 = VGN_NN,
         cpue = VGN_CiscoNN,
         lakesize = Area,
         notes_1 = Comments,
         county = County)%>%
  mutate(total_effort_1_units = "net-nights",
         species_1 = "cisco",
         sampling_method_1 = "vertical_gill_net",
         sampling_method_2 = " Each gang of nets (7 mesh sizes on 5 rollers, set together) is considered a 'Net' and each overnight of fishing a 'Night'. Thus two gangs of nets set for one night is 2 net nights, as is a single gang set for for two nights.",
         target_species = "cisco",
         lakesize_units = "acres",
         survey_type = "targeted")%>%
  mutate(garbage_bin_notes_1 = paste("Cisco_last_year:",C_Lst_yr, sep = " "))%>%
  select(lake_id,
         lake_name,
         county,
         date,
         survey_type,
         target_species,
         sampling_method_1,
         sampling_method_2,
         species_1,
         total_effort_1,
         total_effort_1_units,
         total_count,
         cpue,
         lat_unspec,
         lon_unspec,
         waterbody_type,
         lakesize,
         lakesize_units,
         garbage_bin_notes_1,
         notes_1,
         original_file_name)
  

# Note on Date Set date for Vertical Gill Net cisco surveys conducted by WDNR Fish Research Biologists 2011-2014. Blank if no survey. MM/DD/YYYY format. If there are multiple surveys, the starting date for the last survey is given.
```

Remove surveys that are blank (see note above)
Uncount total catch -> one fish per row
```{r}
wi_cisco_clean_uncount <- wi_cisco_clean %>%
  filter(!is.na(date))%>%
  uncount(total_count)%>%
  mutate(nothing_caught = F)

#uncount removes instances where total catch is 0, so we will add them back in with the code below
nothing_caught <-  wi_cisco_clean %>%
  filter(!is.na(date))%>%
  filter(total_count == 0)%>%
  mutate(species_1 = NA)%>%
  select(-total_count)%>%
  mutate(nothing_caught = T)

wi_cisco_one_fish_per_row <- bind_rows(wi_cisco_clean_uncount, nothing_caught)
```

Final cleaning so it can be ready to merge with the rest of the wi data
```{r}
wi_cisco_final <- wi_cisco_one_fish_per_row %>%
  mutate(date = mdy(date))%>%
  mutate(year = year(date))%>%
  group_by(lake_id, year, survey_type, sampling_method_1)%>%
  mutate(survey_effort = total_effort_1,
         total_effort_ident = cur_group_id())%>%
  mutate(date = as.IDate(date))%>%
  select(-cpue)
```


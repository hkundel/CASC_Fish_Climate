---
title: "MN_Flat_File_March23"
author: "Holly Kundel"
date: "`r Sys.Date()`"
output: html_document
---
libraries
```{r}
library(arrow)
library(readr)
library(dplyr)
library(stringr)
library(data.table)
library(janitor)
library(tidyr)
library(lubridate)

options(scipen = 999)
```


# Update 4/27/2023 
- Using new MN fish age data, and not using previous files

Update 4/4/2023
- Now retains units and notes columns along with inventory information

* Holly's note to self: use dtplyr to convert my dplyr code to data.table (faster and less memory intensive)
```{r}

files_list <- list.files(path = "D:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data", pattern = ".+\\.csv") #grabs only.csv files
files_list

n <- length(files_list)

for(i in 1:n) {
  #i = 1
  filei <- word(gsub(".csv","", files_list[i]), start = -1, sep = fixed("/"))
  #this does those two steps in one package
  assign(filei ,
          data.table(read_csv_arrow(paste0("D:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data/",
                                          files_list[i]))))
  
  # note we want to review a sorted list of column names to check misspelling etc.
  # we still need to use the columns with names like col_name_length_in, or known_units
  
  
  cde %>% # call data explainer file
    filter(`new_file_name`== filei)%>% #keep only the row relevant to this file
    select_if(~ !any(is.na(.))) %>% 
    transpose(keep.names = "newname") %>% 
    rename("oldname" = V1) %>% 
    assign("names", ., envir = .GlobalEnv)
  
  #see if any column names will not have a match! 
  # IF any pop FALSE, force stop and revist of data explainer ()
  # - e.g., named something "total catch" when actual column name was "total_catch"
  print(
    cbind(colnames(get(filei)),
          colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
    )
  )
  
  # break the loop if the current file has column names not in the data explainer
  if (all(cbind(colnames(get(filei)),  colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ])[,2]) == FALSE ) break
  
  # append old col names into new "notes" columns:
  get(filei)[ , (names[ str_detect(newname, "notes") , oldname   ,  ]) := Map(paste, colnames(.SD), .SD, sep = ':') , .SDcols =  names[ str_detect(newname, "notes") , oldname   ,  ] ]
  
  #now rename that file's colnames
  setnames(get(filei), colnames(get(filei)), names[!str_detect(newname,"unique_row_key")] [match(names(get(filei)),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )
  
  #append all other data from data explainer
  unusedbits <- 
    data.table(
      matrix(
        rep(names[ !newname %in% colnames(get(filei)) , oldname , ],
            each = nrow(get(filei))
        ),
        nrow = nrow(get(filei)),
        dimnames = list(rep(NA,nrow(get(filei))),
                        names[ !newname %in% colnames(get(filei)) , newname , ])
        )
      )
  
  #add all not yet used columns from data explainer:
  get(filei)[ , (names[ !newname %in% colnames(get(filei)) , newname , ]) := unusedbits[] ]

  #confirm import of files:  
  print(paste(filei ,"added to workspace" ))  
  
}  

```


3.) Isolate files with “catch” information
4.) pivot_wider catch data so that there is only one fish per line (retain effort info if it is in the same file) then pivor_longer

I know that mn_fish_effot... and mn_gde_gsh_fish_effort... are the same format, so I will combine those first to reduce the number of files we are working with
```{r}
#change lake ID to character string with leading zero
MN_GDE_GSH <- mn_gde_gsh_fish_effort_03May2022 %>%
  mutate(lake_id = as.character(lake_id))%>%
  mutate(lake_id = str_pad(lake_id, 8, side = "left", pad = "0"))

#check if other file has the leading zero on the DOW (lake id)
eight_dow <- mn_aged_fish_v2_20apr2023 %>%
  mutate(leading_zero = str_detect(lake_id, "01\\d\\d\\d\\d\\d\\d"))%>%
  select(lake_id, leading_zero)%>%
  filter(leading_zero == "TRUE") #it does! No need to re-format age data

# properly format lake id (DOW) then will expand so instances of zero catch are added
MN_GN_TN_eff_catch <- bind_rows(mn_fish_effort_03May2022, MN_GDE_GSH)%>%
  mutate(lake_id = str_pad(lake_id, 8, side = "left", pad = "0"))%>%
  pivot_wider(names_from = species.1, values_from = total_count, values_fill = 0) %>% #creates 0s
  select(!contains("frog"))%>% #attempt to drop non-fish species
  select(!contains("crayfish"))%>%
  select(!contains("toad"))%>% #syntax means keep all columns that don't contain "toad"
  select(!contains("turtle"))%>%
  select(!contains("mudpuppy"))%>%
  select(!contains("snake"))%>%
  select(!contains("salamander"))%>%
  select(!contains("muskrat"))%>% #why are muskrats in the dataset?? tf??
  select(!contains("snail"))%>%
  pivot_longer(!1:26, names_to = "species.1", values_to = "total_count")%>% #recreates species and total count columns
  mutate(cpue = (total_count/total_effort_1.1))%>% #updates CPUE column
  mutate(cpue = round(cpue, digits = 2)) #rounds to two digits
  
# Now expand instances of catch >1 to the number of rows stated -> one fish per row
MN_GN_TN_eff_catch_LONG <- uncount(MN_GN_TN_eff_catch, total_count)

#reformat for easier viewing and fix 'cpue' column which doesn't make sense after adding zeros
MN_GN_TN_eff_CPUE <- MN_GN_TN_eff_catch_LONG %>%
  mutate(total_count = 1)%>%
  relocate(any_of(c("survey_id", 
                    "lake_id", 
                    "lake_name", 
                    "date.1", 
                    "year", 
                    "sampling_method_abbrev", 
                    "species.1", 
                    "total_count", 
                    "total_effort_1.1", 
                    "effort_units.1"))) # relocate is the dplyr version of data.table's setcolorder
```

skip code from lines 150 - 200
#______________________________________________________________________________________________________________________
Now add catch files where there is already one fish per row
 - since mn_ef_lmb_smb_catch... are surveys that are targeting bass, I'm not going to add zeros to these surveys because if other species were seen, the would not have been netted
```{r}
#reformat lake IDs to match format and make them all characters
MN_EF_LMB_SMB_Catch <- mn_ef_lmb_smb_catch_26Aug2022 %>%
  mutate(lake_id = str_pad(lake_id, 8, side = "left", pad = "0"))%>%
  select(-cpue) #removing cpue column because it just contains "Y" which isn't useful

All_MN_catch <- MN_GN_TN_eff_catch_LONG %>%
  bind_rows(MN_EF_LMB_SMB_Catch)
```

Add effort and survey information to the catch data that doesn't already have this
- just the electrofishing effort, lake IDs are already formatted properly
```{r}
# first let's identify which columns match 
  # oof may need to add effort to catch and then bind rows?? yep.

#pull column names from the catch data
catch_cols <- as.data.frame(colnames(All_MN_catch))%>%
  rename(Catch = 1)%>%
  mutate(col_check = Catch)

#pull column names from the effort data
ef_effort_cols <- as.data.frame(colnames(mn_ef_lmb_smb_effort_26Aug2022))%>%
  rename(Effort = 1)%>%
  mutate(col_check = Effort)

# join the column name data frames together, and identify overlapping columns
col_comparison <- catch_cols %>%
  full_join(ef_effort_cols, by = "col_check")%>%
  mutate(Join_col = ifelse(!is.na(Catch)&!is.na(Effort), paste(Catch), NA))%>%
  drop_na(Join_col)#identify common columns to use in join by dropping non matches (i.e. NAs)

list(col_comparison$Join_col)

MN_catch_effort <- All_MN_catch %>%
  full_join(mn_ef_lmb_smb_effort_26Aug2022, by = (col_comparison$Join_col))


#check that the effort data was joined appropriately
join_check <- MN_catch_effort %>%
  filter(sampling_method_abbrev == "EF")%>%
  filter(is.na(species.1))

# Okay so I think that I am going to need to join the electrofishing effort to catch before adding that data to the gn and tn data that already had both catch and effort. Because joining this way left us with 4966 NAs for species, meaning that the effort data didn't track well to the catch data. (the original effort df had 6197 obs.) I would maybe expect a few NAs (which would be zeros to add), but not over two thirds of them... 
```

#_______________________________________________________________________________________________________________________

Re-doing above code order of operations
1.) join electrofishing catch and effort data
2.) add electrofishing catch and effort df to MN_GN_TN_eff_catch_LONG
(instead of adding the catch to the above and then pulling in effort)

```{r}
#reformat lake IDs to match format and make them all characters
MN_EF_LMB_SMB_Catch <- mn_ef_lmb_smb_catch_26Aug2022 %>%
  mutate(lake_id = str_pad(lake_id, 8, side = "left", pad = "0"))%>%
  select(-cpue)%>% #removing cpue column because it just contains "Y" which isn't useful
  mutate(date.1 = mdy(date.1))%>%
  mutate(year = year(date.1))

# filter EF effort data for only surveys that list bass as a target species or where target species is NA
MN_EF_Effort_bass <- mn_ef_lmb_smb_effort_26Aug2022 %>%
  mutate(Check = case_when(str_detect(target_species, "LMB") ~ 1,
                           str_detect(target_species, "SMB") ~ 1,
                           is.na(target_species) ~ 1,
                           TRUE ~ 0))%>% #making a column to check which rows to keep based on target species, 1 is keep 0 is remove
  filter(Check == 1)%>%
  select(-Check) #remove 691 effort surveys not targeting bass
#even if other species were targeted (besides bass) we don't have catch data for them and should remove those surveys

#pull column names from the catch data
EF_catch_cols <- as.data.frame(colnames(MN_EF_LMB_SMB_Catch))%>%
  rename(EF_Catch = 1)%>% #names the column something meaningful
  mutate(col_check = EF_Catch) #duplicates column so after the join we can still see the original column lists

#pull column names from the effort data
EF_effort_cols <- as.data.frame(colnames(mn_ef_lmb_smb_effort_26Aug2022))%>%
  rename(EF_Effort = 1)%>%
  mutate(col_check = EF_Effort)

# join the column name data frames together, and identify overlapping columns
col_comparison <- EF_catch_cols %>%
  full_join(EF_effort_cols, by = "col_check")%>%
  mutate(Join_col = ifelse(!is.na(EF_Catch)&!is.na(EF_Effort), paste(EF_Catch), NA))%>%
  drop_na(Join_col)#identify common columns to use in join by dropping non matches (i.e. NAs)
# so a problem with this is that our data explainer tracking columns and notes columns may not match between the two and should NOT be used as a key in the join, will manually identify which columns should be key in the join. For other columns they will need to be consolidated back into one column after the join (unless it does this automatically..?)


# join the electrofishing data based on columns that they share that should be the same (i.e. lake_name should be used, but not "original_file_name)
MN_electofishing <- MN_EF_LMB_SMB_Catch %>%
  full_join(MN_EF_Effort_bass, by = c("survey_id",
                                      "county",
                                      "lake_id",
                                      "lake_name",
                                      "sampling_method_abbrev",
                                      "year",
                                      "state"), suffix = c("_catch", "_effort"))%>% 
  relocate(any_of(c("survey_id", 
                    "lake_id", 
                    "lake_name", 
                    "year", 
                    "sampling_method_abbrev", 
                    "species.1", 
                    "total_count", 
                    "total_effort_1.1", 
                    "effort_units.1",
                    "length.1",
                    "length_unit.1",
                    "age",
                    "target_species",
                    "water_temp",
                    "water_temp_units")))
```
# revist code below to continue troubleshooting the 11,000+ fish obs from EF that don't have a match to effort
%>%
  mutate(Check2 = case_when(is.na(species.1) ~ "no catch",
                           !is.na(species.1) & is.na(total_effort_1.1) ~ "no effort",
                           TRUE ~ "Good"))%>%
  filter(Check2 == "no effort")
  
  # final check
  # group_by(Check2)%>% summarise(Total = n()) no catch is okay. no effort is bad

#check that the join above worked. #check year??
# date is not always matching between the electrofishing catch and effort because there is a start date and end date. I am adding 'year' to the catch and will use that in the join instead


Okay so there is effort data for survey 880626539624000
on Bassett lake in St. Louis county in 2006 but it won't match up to catch
** also should use the date in the catch file NOT the effort file

# Combine all catch and effort data
```{r}
MN_CPUE <- rbindlist(list(MN_GN_TN_eff_CPUE, MN_electofishing), use.names = T, fill = T)
  
  #mn_age_join_1 <- rbindlist(list(mn_aged_fish_1_29Sep2021, mn_aged_fish_2_29Sep2021), use.names = T, fill = T)
```





# Code from
2/2/23
First attempt to use the CASC Data Explainer File to rename columns and create units columns where needed. Uses MN data for test case

### MN is working as of 4/3/23

## Load libraries
```{r, warning = FALSE}
library(readr)
library(readxl)
library(dplyr)
library(stringr)
library(arrow)
library(data.table)
library(googledrive)
library(janitor)
library(tidyr)
library(data.table)
library(tidyr)

```

#Testing Mike's WI code on MN data
```{r}
# find files on Google Drive Desktop
MN_files_list <- list.files(path = "G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data", pattern = ".+\\.csv") #grabs only.csv files

MN_files_list #check that file names look correct

n <- length(MN_files_list)

for(i in 1:n) {
  #i = 1
  assign(gsub(".csv","", MN_files_list[i]),
         data.table(read_csv_arrow(paste0("G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data/",
                                          MN_files_list[i]))))
  
  #consider moving renaming into here!
  
  
  #this does those two steps in one package
# note we want to review a sorted list of column names to check misspelling etc.
cde %>% # call data explainer file
  filter(`new_file_name`== gsub(".csv","", MN_files_list)[i])%>% #keep only the row relevant to this file
  select_if(~ !any(is.na(.))) %>% 
  transpose(keep.names = "newname") %>% 
  rename("oldname" = V1) %>% 
  assign("names", ., envir = .GlobalEnv)

#see if any column names will not have a match! 
# IF any pop FALSE, force stop and revist of data explainer ()
# - e.g., named something "total catch" when actual column name was "total_catch"
print(
cbind(colnames(get(gsub(".csv","", MN_files_list)[i])),
      colnames(get(gsub(".csv","", MN_files_list)[i])) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
)
)

# break the loop if the current file has column names not in the data explainer
if (all(cbind(colnames(get(gsub(".csv","", MN_files_list)[i])),  colnames(get(gsub(".csv","", MN_files_list)[i])) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ])[,2]) == FALSE ) break

#now rename that file's colnames
setnames(get(gsub(".csv","", MN_files_list)[i]), colnames(get(gsub(".csv","", MN_files_list)[i])), names[!str_detect(newname,"unique_row_key")] [match(names(get(gsub(".csv","", MN_files_list)[i])),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )

#confirm import of files:  
print(paste(gsub(".csv","", MN_files_list)[i] ,"added to workspace" ))  

}  
```

File Troubleshooting
```{r}
# gsub(".csv","", MN_files_list[i])
ef_effort <- read_csv(file = "G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/MN_raw_disaggregated_data/mn_ef_lmb_smb_effort_26Aug2022.csv") #note 'fread' had same error as rea_csv_arrow

write_csv(ef_effort, "mn_ef_lmb_smb_effort_26Aug2022.csv")
```

List of Errors and How to Fix them
- Error in setattr(ans, "names", c(keep.names, paste0("V", seq_len(length(ans) -  : 
  'names' attribute [2] must be the same length as the vector [1] 
    - file name is likely different from name in data explainer


#_________________________________________________________________________________________________________________________________________________
Work below this line was pre 3/14/2023

## CASC Data Explainer
### Read in
```{r}
# change E (Mike's drive) to G (Holly's drive)
cde_raw <- data.table(read_excel("G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/CASC_Data_Explainer_for_R_Data_Manipulation.xlsx")) #set as DT on the fly

```

### Prep 

* Data Explainer prep is now done in 'CASC_Data_Explainer_HLK.Rmd'

## State data
### Read in

We eventually want to be able to read this in from google drive directly, right now uses google drive desktops

```{r, warning = FALSE, message = FALSE}  
MN_files_list <- list.files(path = "G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/MN_raw_disaggregated_data", pattern = ".+\\.csv") #only grab csv files

n <- length(MN_files_list) #may want to make it more than just n so it is different for each state??? e.g. "n_mn" ?

# Code from Mike
for(i in 1:n) {
  assign(gsub(".csv","", MN_files_list[i]),
         read_csv(paste0("G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/MN_raw_disaggregated_data/",
                               MN_files_list[i]))) #don't use 'read.csv2, only get one column
} 

# get the list of data sets as data frames in R so they can be looped later

# plus by adding this, you won't have to remove the ".csv" every time you reference the list
MN_file_names <- str_replace(MN_files_list, ".csv", "")   #str_replace and gsub both work the same :) 

```

Process to fix file read in error, no need to run code in this chunk
```{r, echo=FALSE}

#This doesn't work because 'escape_double = TRUE'

for(i in 1:n) {
  assign(gsub(".csv","", MN_files_list[i]),
         data.table(read_csv_arrow(paste0("G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/MN_raw_disaggregated_data/",
                               MN_files_list[i])))) #don't use 'read.csv2, only get one column
} 


#This doesn't work, only loads mn-gde_gsh_fish_effort okay, others don't work

for(i in 1:n) {
  assign(gsub(".csv","", MN_files_list[i]),
         data.table(read_csv_arrow(escape_double = FALSE,(paste0("G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/MN_raw_disaggregated_data/",
                               MN_files_list[i]))))) #don't use 'read.csv2, only get one column
} 

# problem file is 'mn_gde_gsh...'

### fix mn_gde_gsh, was in an improper csv format
#fixed by reading into r with 'read_csv' from 'readr' pkg, and then using 'write_csv'

mn_gde_gsh <- read_csv("G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/MN_raw_disaggregated_data/mn_gde_gsh_fish_effort_03May2022.csv")

#write_csv(mn_gde_gsh, "mn_gde_gs_fish_effort_03May2022_2.csv")
```


Get new column names from data explainer for all files (OUT of Date, see below)
```{r, echo=FALSE}
# THIS METHOD IS OUT OF DATE, SEE BELOW

#for a state file, display column names - 

MN_file_names <- gsub(".csv","", MN_files_list)

#oldnames
old_names <- cde %>% # call data explainer file
  filter(`new_file_name`== MN_file_names[1])%>% #keep only the row relevant to this file
  select_if(~ !any(is.na(.)))%>% #drop columns that contain NA (because that means df doesn't contain that info)
  make_clean_names() %>% 
  assign("oldnames", ., envir = .GlobalEnv)


# select(14:25) #keep only columns of relevance (remove our file tracking and urls)

# display our new names for that set - (esp. need to ID no matches)

cde %>% # call data explainer file
  filter(`new_file_name`== gsub(".csv","", WI_files_list)[1])%>% #keep only the row relevant to this file
  select_if(~ !any(is.na(.)))%>% #drop columns that contain NA (because that means df doesn't contain that info)
  colnames() %>% 
  assign("newnames", ., envir = .GlobalEnv)

cbind(oldnames,newnames)

cde %>% # call data explainer file
  filter(`new_file_name`== gsub(".csv","", WI_files_list)[1])%>% #keep only the row relevant to this file
  select_if(~ !any(is.na(.))) %>% 
  transpose(keep.names = "rn")

colnames(get(gsub(".csv","", WI_files_list)[1]))cde %>% # call data explainer file
  filter(`new_file_name`== gsub(".csv","", WI_files_list)[1])%>% #keep only the row relevant to this file
  select_if(~ !any(is.na(.)))%>% #drop columns that contain NA (because that means df doesn't contain that info)
  colnames() %>% 
  assign("newnames", ., envir = .GlobalEnv)

cbind(oldnames,newnames)
```

New Version of getting new column names from data explainer
```{r}
#code from Mike's WI flat-file work
# note we want to review a sorted list of column names to check misspelling etc.
column_names <- cde %>% # call data explainer file
  filter(`new_file_name`== MN_file_names[1])%>% #keep only the row relevant to this file
  select_if(~ !any(is.na(.))) %>% 
  transpose(keep.names = "newname") %>% 
  rename("oldname" = V1) %>% 
  assign("names", ., envir = .GlobalEnv) # left with two columns of the original file names 'oldname' and the new data explainer names 'newname'


#see if any column names will not have a match! 
# IF any pop FALSE, force stop and revist the data explainer 
# - e.g., named something "total catch" when actual column name was "total_catch"

cbind(colnames(get(MN_file_names[1])),
      colnames(get(MN_file_names[1])) %in% names[ , oldname, ]) #"FALSE" means that our typed name is not a correct column name

# Once all columns are "TRUE" you can move on

names <- names[ match(colnames(get(MN_file_names[1])),
       names[!str_detect(newname,"unique_row_key"),oldname]), ] #check that there are no NAs

### pull in new code from Mike WI work file
```


